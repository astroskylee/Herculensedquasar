{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fecfe9",
   "metadata": {},
   "source": [
    "# PSF Modelling with SVI (STPSF + Pixel Correction)\n",
    "\n",
    "这个 notebook 使用 `Herculens_Tian_JWST.ipynb` 同款的 SVI 思路，\n",
    "对 29 个 `psf_data/*SCIERR.fits` 联合建模。\n",
    "\n",
    "建模结构：\n",
    "- `PSF_model_ss = STPSF_base_ss + correction_ss`\n",
    "- `correction_ss` 来自 `matern_power_spectrum + white-noise Fourier modes`\n",
    "- 在 supersampled 网格建模后，`resize` 到 detector 101x101\n",
    "- 每个观测星点自由度：`x_pos, y_pos, log10_flux, background`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d722183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.ndimage import map_coordinates\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "import numpyro.infer as infer\n",
    "import numpyro.infer.autoguide as autoguide\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "from astropy.io import fits\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "numpyro.enable_x64()\n",
    "\n",
    "from herculens_import_main import (\n",
    "    matern_power_spectrum,\n",
    "    split_scheduler,\n",
    "    SVI_vec,\n",
    "    K_grid,\n",
    "    get_pixel_grid,\n",
    ")\n",
    "from herculens.PointSourceModel.point_source_model import PointSourceModel\n",
    "\n",
    "print(\"JAX devices:\", jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "PIX_SCALE = 0.031\n",
    "DATA_DIR = \"../Data/WFI2033\"\n",
    "PSF_DATA_DIR = \"./psf_data\"\n",
    "BASE_PSF_PATH = os.path.join(DATA_DIR, \"F115W_PSF_stpsf_ss2.fits\")\n",
    "BASE_PSF_EXT = \"OVERSAMP\"   # supersampled extension in STPSF file\n",
    "OUTPUT_DIR = PSF_DATA_DIR\n",
    "\n",
    "SEED = 123\n",
    "MAX_ITERATIONS = 8000\n",
    "NUM_CHAINS = 4\n",
    "NUM_POST_SAMPLES = 300\n",
    "\n",
    "SS_FACTOR = 2\n",
    "BG_ANCHOR_NPIX = 20  # lowest detector pixels in STPSF used as background anchor\n",
    "\n",
    "XPOS_PRIOR_SIGMA = 0.03\n",
    "YPOS_PRIOR_SIGMA = 0.03\n",
    "XPOS_BOUNDS = (-0.30, 0.30)\n",
    "YPOS_BOUNDS = (-0.30, 0.30)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d81db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Load 29 SCIERR cutouts\n",
    "# -----------------------------\n",
    "psf_files = sorted(glob.glob(os.path.join(PSF_DATA_DIR, \"*SCIERR.fits\")))\n",
    "if len(psf_files) == 0:\n",
    "    raise FileNotFoundError(f\"No SCIERR FITS found in {PSF_DATA_DIR}\")\n",
    "\n",
    "print(f\"Found {len(psf_files)} cutouts\")\n",
    "\n",
    "sci_list = []\n",
    "err_list = []\n",
    "flux_loc_list = []\n",
    "bkg_loc_list = []\n",
    "bkg_scale_list = []\n",
    "\n",
    "for fp in psf_files:\n",
    "    with fits.open(fp, memmap=True) as hdul:\n",
    "        sci = np.array(hdul[\"SCI\"].data, dtype=np.float64)\n",
    "        err = np.array(hdul[\"ERR\"].data, dtype=np.float64)\n",
    "\n",
    "    if sci.shape != err.shape:\n",
    "        raise ValueError(f\"Shape mismatch in {fp}: SCI{ sci.shape } vs ERR{ err.shape }\")\n",
    "\n",
    "    valid = np.isfinite(sci) & np.isfinite(err) & (err > 0)\n",
    "    if not np.any(valid):\n",
    "        raise ValueError(f\"No valid pixels in {fp}\")\n",
    "\n",
    "    med_err = float(np.nanmedian(err[valid]))\n",
    "    sci = np.where(valid, sci, 0.0)\n",
    "    err = np.where(valid, err, med_err)\n",
    "    err = np.clip(err, med_err * 0.25, np.inf)\n",
    "\n",
    "    border = np.concatenate([\n",
    "        sci[:5, :].ravel(),\n",
    "        sci[-5:, :].ravel(),\n",
    "        sci[:, :5].ravel(),\n",
    "        sci[:, -5:].ravel(),\n",
    "    ])\n",
    "    bkg = float(np.nanmedian(border))\n",
    "    mad = float(np.nanmedian(np.abs(border - bkg)))\n",
    "    bkg_sigma = max(1.4826 * mad, med_err * 0.1, 1e-6)\n",
    "\n",
    "    flux_est = float(np.sum(np.clip(sci - bkg, 0.0, None)))\n",
    "    flux_est = max(flux_est, 1e-6)\n",
    "\n",
    "    sci_list.append(sci)\n",
    "    err_list.append(err)\n",
    "    flux_loc_list.append(np.log10(flux_est))\n",
    "    bkg_loc_list.append(bkg)\n",
    "    bkg_scale_list.append(bkg_sigma)\n",
    "\n",
    "sci_stack = jnp.array(np.stack(sci_list), dtype=jnp.float64)\n",
    "err_stack = jnp.array(np.stack(err_list), dtype=jnp.float64)\n",
    "flux_loc = jnp.array(np.array(flux_loc_list), dtype=jnp.float64)\n",
    "bkg_loc = jnp.array(np.array(bkg_loc_list), dtype=jnp.float64)\n",
    "bkg_scale = jnp.array(np.array(bkg_scale_list), dtype=jnp.float64)\n",
    "\n",
    "n_star, ny, nx = sci_stack.shape\n",
    "pixel_grid, xgrid, ygrid, x_axis, y_axis, extent, nx_grid, ny_grid = get_pixel_grid(np.zeros((ny, nx)), PIX_SCALE)\n",
    "\n",
    "print(\"data shape:\", sci_stack.shape)\n",
    "print(\"first 5 log10(flux) loc:\", np.array(flux_loc[:5]))\n",
    "print(\"first 5 bkg loc:\", np.array(bkg_loc[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d306e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Load STPSF base and define render helpers\n",
    "# -----------------------------\n",
    "with fits.open(BASE_PSF_PATH, memmap=True) as hdul:\n",
    "    if BASE_PSF_EXT in hdul:\n",
    "        base_psf_ss_np = np.array(hdul[BASE_PSF_EXT].data, dtype=np.float64)\n",
    "    else:\n",
    "        base_psf_ss_np = np.array(hdul[0].data, dtype=np.float64)\n",
    "\n",
    "if base_psf_ss_np.ndim != 2 or base_psf_ss_np.shape[0] != base_psf_ss_np.shape[1]:\n",
    "    raise ValueError(f\"Base PSF must be square 2D, got {base_psf_ss_np.shape}\")\n",
    "\n",
    "if base_psf_ss_np.shape[0] % SS_FACTOR != 0:\n",
    "    raise ValueError(f\"Base PSF size {base_psf_ss_np.shape[0]} not divisible by SS_FACTOR={SS_FACTOR}\")\n",
    "\n",
    "\n",
    "def normalize_kernel(kernel):\n",
    "    kernel = jnp.nan_to_num(kernel, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    kernel = jnp.clip(kernel, 0.0, jnp.inf)\n",
    "    total = jnp.sum(kernel)\n",
    "    return jnp.where(total > 0.0, kernel / total, kernel)\n",
    "\n",
    "\n",
    "def downsample_mean(kernel_ss, factor=2):\n",
    "    ny_ss, nx_ss = kernel_ss.shape\n",
    "    return kernel_ss.reshape(ny_ss // factor, factor, nx_ss // factor, factor).mean(axis=(1, 3))\n",
    "\n",
    "\n",
    "def anchor_match_detector_background(psf_det_model, anchor_y, anchor_x, target_mean, eps=1e-12):\n",
    "    model_anchor_mean = jnp.mean(psf_det_model[anchor_y, anchor_x])\n",
    "    delta = model_anchor_mean - target_mean\n",
    "    psf_shifted = psf_det_model - delta\n",
    "    psf_shifted = jnp.clip(psf_shifted, eps, jnp.inf)\n",
    "    psf_shifted = psf_shifted / jnp.sum(psf_shifted)\n",
    "    return psf_shifted, delta, model_anchor_mean\n",
    "\n",
    "\n",
    "point_source_model = PointSourceModel([\"IMAGE_POSITIONS\"])\n",
    "\n",
    "\n",
    "def render_point_sources_from_kernel(kernel_det, theta_x, theta_y, amplitude):\n",
    "    theta_x = jnp.atleast_1d(theta_x)\n",
    "    theta_y = jnp.atleast_1d(theta_y)\n",
    "    amplitude = jnp.atleast_1d(amplitude)\n",
    "\n",
    "    x_pix, y_pix = pixel_grid.map_coord2pix(theta_x, theta_y)\n",
    "    kernel_t = kernel_det.T\n",
    "\n",
    "    nx_det, ny_det = pixel_grid.num_pixel_axes\n",
    "    xrange = jnp.arange(nx_det) + kernel_t.shape[0] // 2\n",
    "    yrange = jnp.arange(ny_det) + kernel_t.shape[1] // 2\n",
    "\n",
    "    result = jnp.zeros((nx_det, ny_det), dtype=kernel_det.dtype)\n",
    "    for x0, y0, amp in zip(x_pix, y_pix, amplitude):\n",
    "        xy_grid = jnp.meshgrid(xrange - x0, yrange - y0)\n",
    "        result = result + amp * map_coordinates(kernel_t, xy_grid, order=1, mode=\"nearest\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def render_single_star(kernel_det, x_pos, y_pos, flux, background):\n",
    "    kwargs_point_source = [{\"ra\": x_pos, \"dec\": y_pos, \"amp\": flux}]\n",
    "    theta_x_list, theta_y_list, amp_list = point_source_model.get_multiple_images(\n",
    "        kwargs_point_source,\n",
    "        kwargs_lens=None,\n",
    "        kwargs_solver=None,\n",
    "        k=0,\n",
    "        with_amplitude=True,\n",
    "        zero_amp_duplicates=False,\n",
    "    )\n",
    "    image = render_point_sources_from_kernel(kernel_det, theta_x_list[0], theta_y_list[0], amp_list[0])\n",
    "    return image + background\n",
    "\n",
    "\n",
    "base_psf_ss = normalize_kernel(jnp.array(base_psf_ss_np, dtype=jnp.float64))\n",
    "base_psf_det = normalize_kernel(downsample_mean(base_psf_ss, factor=SS_FACTOR))\n",
    "\n",
    "anchor_npix = int(min(BG_ANCHOR_NPIX, int(base_psf_det.size)))\n",
    "base_psf_det_np = np.array(base_psf_det)\n",
    "anchor_idx_np = np.argsort(base_psf_det_np.reshape(-1))[:anchor_npix]\n",
    "anchor_y_np, anchor_x_np = np.unravel_index(anchor_idx_np, base_psf_det_np.shape)\n",
    "anchor_y = jnp.array(anchor_y_np, dtype=jnp.int32)\n",
    "anchor_x = jnp.array(anchor_x_np, dtype=jnp.int32)\n",
    "base_anchor_mean = jnp.mean(base_psf_det[anchor_y, anchor_x])\n",
    "\n",
    "anchor_mask_np = np.zeros(base_psf_det_np.shape, dtype=np.float32)\n",
    "anchor_mask_np[anchor_y_np, anchor_x_np] = 1.0\n",
    "\n",
    "k_grid_ss = K_grid(base_psf_ss.shape)\n",
    "k_values_ss = jnp.array(k_grid_ss.k, dtype=jnp.float64)\n",
    "\n",
    "print(\"base ss shape:\", base_psf_ss.shape)\n",
    "print(\"base det shape:\", base_psf_det.shape)\n",
    "print(f\"anchor pixels: {anchor_npix}, target mean={float(base_anchor_mean):.3e}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(np.array(base_psf_ss), origin=\"lower\", norm=\"log\")\n",
    "axes[0].set_title(\"Base STPSF (ss grid)\")\n",
    "axes[1].imshow(np.array(base_psf_det), origin=\"lower\", norm=\"log\")\n",
    "axes[1].set_title(\"Base STPSF (detector grid)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Model: STPSF + (Matern + WN Fourier correction) + resize + per-star nuisance\n",
    "# Flux is solved analytically per star (weighted least squares), not sampled.\n",
    "# Correction field is projected to have zero 0th/1st moments (no total-flux or centroid drift).\n",
    "# -----------------------------\n",
    "def weighted_ls_flux(unit_model_stack, data_minus_bkg, err_stack, eps=1e-12):\n",
    "    inv_var = 1.0 / (err_stack**2 + eps)\n",
    "    numer = jnp.sum(unit_model_stack * data_minus_bkg * inv_var, axis=(1, 2))\n",
    "    denom = jnp.sum((unit_model_stack**2) * inv_var, axis=(1, 2)) + eps\n",
    "    flux = numer / denom\n",
    "    # enforce physically positive point-source flux\n",
    "    return jnp.clip(flux, eps, jnp.inf)\n",
    "\n",
    "\n",
    "def project_zero_moments(corr, eps=1e-12):\n",
    "    ny, nx = corr.shape\n",
    "    yy, xx = jnp.indices((ny, nx), dtype=corr.dtype)\n",
    "    xx = xx - (nx - 1) / 2.0\n",
    "    yy = yy - (ny - 1) / 2.0\n",
    "\n",
    "    b0 = jnp.ones_like(corr)\n",
    "    bx = xx\n",
    "    by = yy\n",
    "\n",
    "    d = corr.reshape(-1)\n",
    "    B = jnp.stack([b0.reshape(-1), bx.reshape(-1), by.reshape(-1)], axis=1)  # (N, 3)\n",
    "\n",
    "    BtB = B.T @ B\n",
    "    Btd = B.T @ d\n",
    "    coeff = jnp.linalg.solve(BtB + eps * jnp.eye(3, dtype=corr.dtype), Btd)\n",
    "    d_proj = d - B @ coeff\n",
    "    return d_proj.reshape(ny, nx)\n",
    "\n",
    "\n",
    "def model_psf_svi(sci_data, err_data, flux_loc, bkg_loc, bkg_scale, base_psf_ss, k_values):\n",
    "    _ = flux_loc  # kept for function interface compatibility\n",
    "\n",
    "    corr_dict = matern_power_spectrum(\n",
    "        \"PSF correction\",\n",
    "        \"psf_corr\",\n",
    "        k_values,\n",
    "        n_value=None,\n",
    "        positive=False,\n",
    "    )\n",
    "    corr_ss_raw = corr_dict[\"pixels\"]\n",
    "    corr_ss = project_zero_moments(corr_ss_raw)\n",
    "    numpyro.deterministic(\"pixels_psf_corr_proj\", corr_ss)\n",
    "\n",
    "    psf_ss_raw = base_psf_ss + corr_ss\n",
    "    psf_ss_pos = jax.nn.softplus(100.0 * psf_ss_raw) / 100.0\n",
    "    psf_ss_model = psf_ss_pos / jnp.sum(psf_ss_pos)\n",
    "    numpyro.deterministic(\"psf_ss_model\", psf_ss_model)\n",
    "\n",
    "    psf_det_model_prebg = downsample_mean(psf_ss_model, factor=SS_FACTOR)\n",
    "    psf_det_model_prebg = psf_det_model_prebg / jnp.sum(psf_det_model_prebg)\n",
    "    numpyro.deterministic(\"psf_det_model_prebg\", psf_det_model_prebg)\n",
    "\n",
    "    psf_det_model, psf_det_bg_anchor_delta, psf_det_bg_anchor_mean_pre = anchor_match_detector_background(\n",
    "        psf_det_model_prebg,\n",
    "        anchor_y,\n",
    "        anchor_x,\n",
    "        base_anchor_mean,\n",
    "    )\n",
    "    numpyro.deterministic(\"psf_det_bg_anchor_delta\", psf_det_bg_anchor_delta)\n",
    "    numpyro.deterministic(\"psf_det_bg_anchor_mean_pre\", psf_det_bg_anchor_mean_pre)\n",
    "    numpyro.deterministic(\"psf_det_bg_anchor_mean_post\", jnp.mean(psf_det_model[anchor_y, anchor_x]))\n",
    "    numpyro.deterministic(\"psf_det_bg_anchor_target\", base_anchor_mean)\n",
    "    numpyro.deterministic(\"psf_det_model\", psf_det_model)\n",
    "\n",
    "    base_det = downsample_mean(base_psf_ss, factor=SS_FACTOR)\n",
    "    base_det = base_det / jnp.sum(base_det)\n",
    "    numpyro.deterministic(\"psf_corr_ss_eff\", psf_ss_model - base_psf_ss)\n",
    "    numpyro.deterministic(\"psf_corr_det_eff\", psf_det_model - base_det)\n",
    "\n",
    "    n_star = sci_data.shape[0]\n",
    "    with numpyro.plate(\"stars\", n_star):\n",
    "        x_pos = numpyro.sample(\n",
    "            \"x_pos\",\n",
    "            dist.TruncatedNormal(\n",
    "                loc=jnp.zeros(n_star),\n",
    "                scale=XPOS_PRIOR_SIGMA,\n",
    "                low=XPOS_BOUNDS[0],\n",
    "                high=XPOS_BOUNDS[1],\n",
    "            ),\n",
    "        )\n",
    "        y_pos = numpyro.sample(\n",
    "            \"y_pos\",\n",
    "            dist.TruncatedNormal(\n",
    "                loc=jnp.zeros(n_star),\n",
    "                scale=YPOS_PRIOR_SIGMA,\n",
    "                low=YPOS_BOUNDS[0],\n",
    "                high=YPOS_BOUNDS[1],\n",
    "            ),\n",
    "        )\n",
    "        background = numpyro.sample(\n",
    "            \"background\",\n",
    "            dist.Normal(loc=bkg_loc, scale=bkg_scale),\n",
    "        )\n",
    "\n",
    "    # Render unit-flux stars on detector grid; solve amplitudes analytically\n",
    "    unit_model_stack = jax.vmap(render_single_star, in_axes=(None, 0, 0, 0, 0))(\n",
    "        psf_det_model,\n",
    "        x_pos,\n",
    "        y_pos,\n",
    "        jnp.ones_like(x_pos),\n",
    "        jnp.zeros_like(background),\n",
    "    )\n",
    "    data_minus_bkg = sci_data - background[:, None, None]\n",
    "    flux_opt = weighted_ls_flux(unit_model_stack, data_minus_bkg, err_data)\n",
    "    numpyro.deterministic(\"flux_opt\", flux_opt)\n",
    "    numpyro.deterministic(\"log10_flux_opt\", jnp.log10(flux_opt))\n",
    "\n",
    "    model_stack = unit_model_stack * flux_opt[:, None, None] + background[:, None, None]\n",
    "    numpyro.sample(\"obs\", dist.Normal(model_stack, err_data), obs=sci_data)\n",
    "\n",
    "\n",
    "rng_key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "init_fun = infer.init_to_median(num_samples=15)\n",
    "guide = autoguide.AutoDiagonalNormal(model_psf_svi, init_loc_fn=init_fun, init_scale=0.02)\n",
    "\n",
    "scheduler = split_scheduler(MAX_ITERATIONS, init_value=0.01, transition_steps=[200, 20])\n",
    "optim = optax.adabelief(learning_rate=scheduler)\n",
    "loss = infer.TraceMeanField_ELBO()\n",
    "\n",
    "svi = SVI_vec(model_psf_svi, guide, optim, loss)\n",
    "\n",
    "svi_results = svi.run(\n",
    "    rng_key,\n",
    "    NUM_CHAINS,\n",
    "    MAX_ITERATIONS,\n",
    "    sci_stack,\n",
    "    err_stack,\n",
    "    flux_loc,\n",
    "    bkg_loc,\n",
    "    bkg_scale,\n",
    "    base_psf_ss,\n",
    "    k_values_ss,\n",
    "    stable_update=True,\n",
    ")\n",
    "\n",
    "losses_np = np.array(jax.device_get(svi_results.losses))\n",
    "final_losses = losses_np[:, -1]\n",
    "best_chain = int(np.argmin(final_losses))\n",
    "print(\"Final losses:\", final_losses)\n",
    "print(\"Best chain:\", best_chain)\n",
    "\n",
    "params_best = jax.tree.map(lambda v: v[best_chain], svi_results.params)\n",
    "median_best = guide.median(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Posterior samples and required posteriors\n",
    "# - pixel grid posterior: pixels_psf_corr (raw) and pixels_psf_corr_proj (projected)\n",
    "# - power-spectrum posterior: n_psf_corr, rho_psf_corr (and sigma_psf_corr)\n",
    "# - deterministic model PSF images for direct posterior median (SVI)\n",
    "# -----------------------------\n",
    "rng_key, sample_key, pred_key = jax.random.split(rng_key, 3)\n",
    "\n",
    "posterior_latent = guide.sample_posterior(\n",
    "    sample_key,\n",
    "    params_best,\n",
    "    sample_shape=(NUM_POST_SAMPLES,),\n",
    ")\n",
    "\n",
    "return_sites = [\n",
    "    \"psf_ss_model\",\n",
    "    \"psf_det_model\",\n",
    "    \"psf_det_model_prebg\",\n",
    "    \"psf_det_bg_anchor_delta\",\n",
    "    \"psf_det_bg_anchor_mean_pre\",\n",
    "    \"psf_det_bg_anchor_mean_post\",\n",
    "    \"psf_det_bg_anchor_target\",\n",
    "    \"pixels_psf_corr\",\n",
    "    \"pixels_psf_corr_proj\",\n",
    "    \"psf_corr_ss_eff\",\n",
    "    \"psf_corr_det_eff\",\n",
    "    \"n_psf_corr\",\n",
    "    \"rho_psf_corr\",\n",
    "    \"sigma_psf_corr\",\n",
    "    \"x_pos\",\n",
    "    \"y_pos\",\n",
    "    \"background\",\n",
    "    \"flux_opt\",\n",
    "    \"log10_flux_opt\",\n",
    "]\n",
    "\n",
    "predictive = infer.Predictive(\n",
    "    model_psf_svi,\n",
    "    posterior_samples=posterior_latent,\n",
    "    return_sites=return_sites,\n",
    ")\n",
    "\n",
    "posterior = predictive(\n",
    "    pred_key,\n",
    "    sci_stack,\n",
    "    err_stack,\n",
    "    flux_loc,\n",
    "    bkg_loc,\n",
    "    bkg_scale,\n",
    "    base_psf_ss,\n",
    "    k_values_ss,\n",
    ")\n",
    "\n",
    "n_post = np.array(jax.device_get(posterior[\"n_psf_corr\"]))[:, 0]\n",
    "rho_post = np.array(jax.device_get(posterior[\"rho_psf_corr\"]))[:, 0]\n",
    "sigma_post = np.array(jax.device_get(posterior[\"sigma_psf_corr\"]))[:, 0]\n",
    "\n",
    "psf_ss_median = np.median(np.array(jax.device_get(posterior[\"psf_ss_model\"])), axis=0)\n",
    "psf_det_median = np.median(np.array(jax.device_get(posterior[\"psf_det_model\"])), axis=0)\n",
    "pixcorr_median = np.median(np.array(jax.device_get(posterior[\"pixels_psf_corr_proj\"])), axis=0)\n",
    "\n",
    "anchor_delta_post = np.array(jax.device_get(posterior[\"psf_det_bg_anchor_delta\"]))\n",
    "anchor_mean_pre_post = np.array(jax.device_get(posterior[\"psf_det_bg_anchor_mean_pre\"]))\n",
    "anchor_mean_post_post = np.array(jax.device_get(posterior[\"psf_det_bg_anchor_mean_post\"]))\n",
    "anchor_target_post = np.array(jax.device_get(posterior[\"psf_det_bg_anchor_target\"]))\n",
    "\n",
    "anchor_target_mean = float(np.median(anchor_target_post))\n",
    "anchor_model_mean_from_psf = float(np.mean(psf_det_median[anchor_y_np, anchor_x_np]))\n",
    "\n",
    "summary = {\n",
    "    \"n_median\": float(np.median(n_post)),\n",
    "    \"n_p16\": float(np.percentile(n_post, 16)),\n",
    "    \"n_p84\": float(np.percentile(n_post, 84)),\n",
    "    \"rho_median\": float(np.median(rho_post)),\n",
    "    \"rho_p16\": float(np.percentile(rho_post, 16)),\n",
    "    \"rho_p84\": float(np.percentile(rho_post, 84)),\n",
    "    \"sigma_median\": float(np.median(sigma_post)),\n",
    "    \"sigma_p16\": float(np.percentile(sigma_post, 16)),\n",
    "    \"sigma_p84\": float(np.percentile(sigma_post, 84)),\n",
    "    \"anchor_target_mean\": anchor_target_mean,\n",
    "    \"anchor_model_mean_pre_median\": float(np.median(anchor_mean_pre_post)),\n",
    "    \"anchor_model_mean_post_median\": float(np.median(anchor_mean_post_post)),\n",
    "    \"anchor_model_mean_from_psf_median\": anchor_model_mean_from_psf,\n",
    "    \"anchor_delta_median\": float(np.median(anchor_delta_post)),\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"anchor mean (target/model_post_from_psf): \"\n",
    "    f\"{summary['anchor_target_mean']:.3e} / {summary['anchor_model_mean_from_psf_median']:.3e}\"\n",
    ")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d10ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Visual diagnostics\n",
    "# -----------------------------\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "\n",
    "for i in range(losses_np.shape[0]):\n",
    "    axes[0, 0].plot(losses_np[i], alpha=0.7, label=f\"chain {i}\")\n",
    "axes[0, 0].set_yscale(\"asinh\")\n",
    "axes[0, 0].set_title(\"SVI loss\")\n",
    "axes[0, 0].legend(loc=\"best\", fontsize=8)\n",
    "\n",
    "im1 = axes[0, 1].imshow(np.array(base_psf_det), origin=\"lower\", norm=\"log\")\n",
    "axes[0, 1].set_title(\"Base STPSF (det)\")\n",
    "plt.colorbar(im1, ax=axes[0, 1], fraction=0.046, pad=0.04)\n",
    "\n",
    "im2 = axes[0, 2].imshow(psf_det_median, origin=\"lower\", norm=\"log\")\n",
    "axes[0, 2].set_title(\"Model PSF median (det)\")\n",
    "plt.colorbar(im2, ax=axes[0, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "im3 = axes[1, 0].imshow(pixcorr_median, origin=\"lower\")\n",
    "axes[1, 0].set_title(\"pixels_psf_corr median (ss)\")\n",
    "plt.colorbar(im3, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
    "\n",
    "axes[1, 1].hist(n_post, bins=30, alpha=0.8)\n",
    "axes[1, 1].set_title(\"Posterior of n_psf_corr\")\n",
    "\n",
    "axes[1, 2].hist(rho_post, bins=30, alpha=0.8)\n",
    "axes[1, 2].set_xscale(\"log\")\n",
    "axes[1, 2].set_title(\"Posterior of rho_psf_corr\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Save SVI outputs (no HMC)\n",
    "# -----------------------------\n",
    "output_fits = os.path.join(OUTPUT_DIR, \"PSF_model.fits\")\n",
    "output_info = os.path.join(OUTPUT_DIR, \"PSF_model_info_svi.npz\")\n",
    "\n",
    "# noise grid used to generate correction: posterior latent pixels_wn\n",
    "pixels_wn_post = np.array(jax.device_get(posterior_latent[\"pixels_wn_psf_corr\"]))\n",
    "pixels_wn_median = np.median(pixels_wn_post, axis=0)\n",
    "\n",
    "# projected/effective correction medians\n",
    "corr_proj_median = np.median(np.array(jax.device_get(posterior[\"pixels_psf_corr_proj\"])), axis=0)\n",
    "corr_eff_ss_median = np.median(np.array(jax.device_get(posterior[\"psf_corr_ss_eff\"])), axis=0)\n",
    "corr_eff_det_median = np.median(np.array(jax.device_get(posterior[\"psf_corr_det_eff\"])), axis=0)\n",
    "\n",
    "hdr = fits.Header()\n",
    "hdr[\"NSTAR\"] = int(n_star)\n",
    "hdr[\"PIXSCALE\"] = float(PIX_SCALE)\n",
    "hdr[\"SSFACT\"] = int(SS_FACTOR)\n",
    "hdr[\"NPOST\"] = int(NUM_POST_SAMPLES)\n",
    "hdr[\"NMED\"] = float(summary[\"n_median\"])\n",
    "hdr[\"RHOMED\"] = float(summary[\"rho_median\"])\n",
    "hdr[\"SIGMED\"] = float(summary[\"sigma_median\"])\n",
    "hdr[\"ANPIX\"] = int(anchor_npix)\n",
    "hdr[\"ANTGT\"] = float(summary[\"anchor_target_mean\"])\n",
    "hdr[\"ANMOD\"] = float(summary[\"anchor_model_mean_from_psf_median\"])\n",
    "hdr[\"ANDELTA\"] = float(summary[\"anchor_delta_median\"])\n",
    "\n",
    "hdul = fits.HDUList([\n",
    "    fits.PrimaryHDU(header=hdr),\n",
    "    fits.ImageHDU(data=np.array(psf_ss_median, dtype=np.float32), name=\"SS_PSF_MODEL\"),\n",
    "    fits.ImageHDU(data=np.array(psf_det_median, dtype=np.float32), name=\"DET_PSF_MODEL\"),\n",
    "    fits.ImageHDU(data=np.array(corr_proj_median, dtype=np.float32), name=\"CORR_PROJ_SS\"),\n",
    "    fits.ImageHDU(data=np.array(corr_eff_ss_median, dtype=np.float32), name=\"CORR_EFF_SS\"),\n",
    "    fits.ImageHDU(data=np.array(corr_eff_det_median, dtype=np.float32), name=\"CORR_EFF_DET\"),\n",
    "    fits.ImageHDU(data=np.array(pixels_wn_median, dtype=np.float32), name=\"NOISE_WN_MED\"),\n",
    "    fits.ImageHDU(data=np.array(k_values_ss, dtype=np.float32), name=\"K_GRID\"),\n",
    "    fits.ImageHDU(data=np.array(anchor_mask_np, dtype=np.float32), name=\"ANCHOR_MASK\"),\n",
    "    fits.ImageHDU(data=np.array(np.vstack([anchor_y_np, anchor_x_np]), dtype=np.int16), name=\"ANCHOR_YX\"),\n",
    "])\n",
    "hdul.writeto(output_fits, overwrite=True)\n",
    "\n",
    "np.savez(\n",
    "    output_info,\n",
    "    n_post=n_post,\n",
    "    rho_post=rho_post,\n",
    "    sigma_post=sigma_post,\n",
    "    n_median=np.float64(summary[\"n_median\"]),\n",
    "    rho_median=np.float64(summary[\"rho_median\"]),\n",
    "    sigma_median=np.float64(summary[\"sigma_median\"]),\n",
    "    pixels_wn_median=np.array(pixels_wn_median, dtype=np.float32),\n",
    "    pixels_corr_proj_median=np.array(corr_proj_median, dtype=np.float32),\n",
    "    psf_det_median=np.array(psf_det_median, dtype=np.float32),\n",
    "    anchor_y=np.array(anchor_y_np, dtype=np.int16),\n",
    "    anchor_x=np.array(anchor_x_np, dtype=np.int16),\n",
    "    anchor_target_mean=np.float64(summary[\"anchor_target_mean\"]),\n",
    "    anchor_model_mean_from_psf=np.float64(summary[\"anchor_model_mean_from_psf_median\"]),\n",
    "    anchor_delta_median=np.float64(summary[\"anchor_delta_median\"]),\n",
    ")\n",
    "\n",
    "print(\"saved:\", output_fits)\n",
    "print(\"saved:\", output_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Result display requested:\n",
    "# - STPSF psf and modeled psf\n",
    "# - global correction field\n",
    "# - all stars: star, model, residual\n",
    "# -----------------------------\n",
    "x_med = np.median(np.array(jax.device_get(posterior[\"x_pos\"])), axis=0)\n",
    "y_med = np.median(np.array(jax.device_get(posterior[\"y_pos\"])), axis=0)\n",
    "flux_med = np.median(np.array(jax.device_get(posterior[\"flux_opt\"])), axis=0)\n",
    "bkg_med = np.median(np.array(jax.device_get(posterior[\"background\"])), axis=0)\n",
    "\n",
    "\n",
    "# Model PSF-only image for each star (background fixed to 0)\n",
    "psf_only_med = jax.vmap(render_single_star, in_axes=(None, 0, 0, 0, 0))(\n",
    "    jnp.array(psf_det_median),\n",
    "    jnp.array(x_med),\n",
    "    jnp.array(y_med),\n",
    "    jnp.array(flux_med),\n",
    "    jnp.zeros_like(jnp.array(bkg_med)),\n",
    ")\n",
    "psf_only_med = np.array(jax.device_get(psf_only_med))\n",
    "\n",
    "data_np = np.array(jax.device_get(sci_stack))\n",
    "err_np = np.array(jax.device_get(err_stack))\n",
    "bkg_cube = bkg_med[:, None, None]\n",
    "\n",
    "star_img = data_np - bkg_cube\n",
    "residual = (data_np - psf_only_med - bkg_cube) / err_np\n",
    "\n",
    "# (A) STPSF detector PSF and model detector PSF\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n",
    "im0 = axes[0].imshow(np.array(base_psf_det), origin=\"lower\", norm=\"log\")\n",
    "axes[0].set_title(\"STPSF (detector)\")\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "im1 = axes[1].imshow(np.array(psf_det_median), origin=\"lower\", norm=\"log\")\n",
    "axes[1].set_title(\"Model PSF (detector)\")\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "\n",
    "# (B) Global correction field (single field, not per-star)\n",
    "global_corr_ss = np.array(psf_ss_median) - np.array(base_psf_ss)\n",
    "global_corr_det = np.array(psf_det_median) - np.array(base_psf_det)\n",
    "\n",
    "abs_corr_ss = np.max(np.abs(global_corr_ss))\n",
    "if abs_corr_ss <= 0:\n",
    "    abs_corr_ss = 1.0\n",
    "abs_corr_det = np.max(np.abs(global_corr_det))\n",
    "if abs_corr_det <= 0:\n",
    "    abs_corr_det = 1.0\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "im2 = axes[0].imshow(global_corr_ss, origin=\"lower\", cmap=\"coolwarm\", vmin=-abs_corr_ss, vmax=abs_corr_ss)\n",
    "axes[0].set_title(\"Global correction field (SS)\")\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "plt.colorbar(im2, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "im3 = axes[1].imshow(global_corr_det, origin=\"lower\", cmap=\"coolwarm\", vmin=-abs_corr_det, vmax=abs_corr_det)\n",
    "axes[1].set_title(\"Global correction field (detector)\")\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "plt.colorbar(im3, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "\n",
    "# (C) Show all stars with 3 panels each: star / model / residual\n",
    "n_show = star_img.shape[0]\n",
    "chunk_size = 7  # rows per figure\n",
    "\n",
    "star_vmin, star_vmax = np.percentile(star_img, [1.0, 99.5])\n",
    "model_vmin, model_vmax = np.percentile(psf_only_med, [1.0, 99.5])\n",
    "\n",
    "for start in range(0, n_show, chunk_size):\n",
    "    stop = min(start + chunk_size, n_show)\n",
    "    nrows = stop - start\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, 3, figsize=(9.5, 2.6 * nrows), constrained_layout=True)\n",
    "    axes = np.array(axes)\n",
    "    if nrows == 1:\n",
    "        axes = axes[None, :]\n",
    "\n",
    "    for r, i in enumerate(range(start, stop)):\n",
    "        im_star = axes[r, 0].imshow(star_img[i], origin=\"lower\", cmap=\"viridis\", vmin=star_vmin, vmax=star_vmax)\n",
    "        axes[r, 0].set_title(f\"star {i}: data-bkg\", fontsize=9)\n",
    "\n",
    "        im_model = axes[r, 1].imshow(psf_only_med[i], origin=\"lower\", cmap=\"viridis\", vmin=model_vmin, vmax=model_vmax)\n",
    "        axes[r, 1].set_title(\"model\", fontsize=9)\n",
    "\n",
    "        im_res = axes[r, 2].imshow(residual[i], origin=\"lower\", cmap=\"bwr\", vmin=-3, vmax=3)\n",
    "        axes[r, 2].set_title(\"residual\", fontsize=9)\n",
    "\n",
    "        for c in range(3):\n",
    "            axes[r, c].set_xticks([])\n",
    "            axes[r, c].set_yticks([])\n",
    "\n",
    "    fig.colorbar(im_star, ax=axes[:, 0].tolist(), fraction=0.02, pad=0.01)\n",
    "    fig.colorbar(im_model, ax=axes[:, 1].tolist(), fraction=0.02, pad=0.01)\n",
    "    fig.colorbar(im_res, ax=axes[:, 2].tolist(), fraction=0.02, pad=0.01)\n",
    "\n",
    "    fig.suptitle(f\"Stars {start} - {stop-1}: star / model / residual\", fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}