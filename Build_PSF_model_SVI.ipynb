{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fecfe9",
   "metadata": {},
   "source": [
    "# PSF Modelling with SVI (STPSF + Pixel Correction)\n",
    "\n",
    "这个 notebook 使用 `Herculens_Tian_JWST.ipynb` 同款的 SVI 思路，\n",
    "对 29 个 `psf_data/*SCIERR.fits` 联合建模。\n",
    "\n",
    "建模结构：\n",
    "- `PSF_model_ss = STPSF_base_ss + correction_ss`\n",
    "- `correction_ss` 来自 `matern_power_spectrum + white-noise Fourier modes`\n",
    "- 在 supersampled 网格建模后，`resize` 到 detector 101x101\n",
    "- 每个观测星点自由度：`x_pos, y_pos, log10_flux, background`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d722183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.ndimage import map_coordinates\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "import numpyro.infer as infer\n",
    "import numpyro.infer.autoguide as autoguide\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "from astropy.io import fits\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "numpyro.enable_x64()\n",
    "\n",
    "from herculens_import_main import (\n",
    "    matern_power_spectrum,\n",
    "    split_scheduler,\n",
    "    SVI_vec,\n",
    "    K_grid,\n",
    "    get_pixel_grid,\n",
    ")\n",
    "from herculens.PointSourceModel.point_source_model import PointSourceModel\n",
    "\n",
    "print(\"JAX devices:\", jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "PIX_SCALE = 0.031\n",
    "DATA_DIR = \"../Data/WFI2033\"\n",
    "PSF_DATA_DIR = \"./psf_data\"\n",
    "BASE_PSF_PATH = os.path.join(DATA_DIR, \"F115W_PSF_stpsf_ss2.fits\")\n",
    "BASE_PSF_EXT = \"OVERSAMP\"   # supersampled extension in STPSF file\n",
    "RESULT_DIR = \"./result\"\n",
    "OUTPUT_DIR = RESULT_DIR\n",
    "\n",
    "SEED = 123\n",
    "MAX_ITERATIONS = 8000\n",
    "NUM_CHAINS = 4\n",
    "NUM_POST_SAMPLES = 300\n",
    "\n",
    "SS_FACTOR = 2\n",
    "\n",
    "XPOS_PRIOR_SIGMA = 0.03\n",
    "YPOS_PRIOR_SIGMA = 0.03\n",
    "XPOS_BOUNDS = (-0.30, 0.30)\n",
    "YPOS_BOUNDS = (-0.30, 0.30)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d81db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Load 29 SCIERR cutouts\n",
    "# -----------------------------\n",
    "psf_files = sorted(glob.glob(os.path.join(PSF_DATA_DIR, \"*SCIERR.fits\")))\n",
    "if len(psf_files) == 0:\n",
    "    raise FileNotFoundError(f\"No SCIERR FITS found in {PSF_DATA_DIR}\")\n",
    "\n",
    "print(f\"Found {len(psf_files)} cutouts\")\n",
    "\n",
    "sci_list = []\n",
    "err_list = []\n",
    "flux_loc_list = []\n",
    "bkg_loc_list = []\n",
    "bkg_scale_list = []\n",
    "\n",
    "for fp in psf_files:\n",
    "    with fits.open(fp, memmap=True) as hdul:\n",
    "        sci = np.array(hdul[\"SCI\"].data, dtype=np.float64)\n",
    "        err = np.array(hdul[\"ERR\"].data, dtype=np.float64)\n",
    "\n",
    "    if sci.shape != err.shape:\n",
    "        raise ValueError(f\"Shape mismatch in {fp}: SCI{ sci.shape } vs ERR{ err.shape }\")\n",
    "\n",
    "    valid = np.isfinite(sci) & np.isfinite(err) & (err > 0)\n",
    "    if not np.any(valid):\n",
    "        raise ValueError(f\"No valid pixels in {fp}\")\n",
    "\n",
    "    med_err = float(np.nanmedian(err[valid]))\n",
    "    sci = np.where(valid, sci, 0.0)\n",
    "    err = np.where(valid, err, med_err)\n",
    "    err = np.clip(err, med_err * 0.25, np.inf)\n",
    "\n",
    "    border = np.concatenate([\n",
    "        sci[:5, :].ravel(),\n",
    "        sci[-5:, :].ravel(),\n",
    "        sci[:, :5].ravel(),\n",
    "        sci[:, -5:].ravel(),\n",
    "    ])\n",
    "    bkg = float(np.nanmedian(border))\n",
    "    mad = float(np.nanmedian(np.abs(border - bkg)))\n",
    "    bkg_sigma = max(1.4826 * mad, med_err * 0.1, 1e-6)\n",
    "\n",
    "    flux_est = float(np.sum(np.clip(sci - bkg, 0.0, None)))\n",
    "    flux_est = max(flux_est, 1e-6)\n",
    "\n",
    "    sci_list.append(sci)\n",
    "    err_list.append(err)\n",
    "    flux_loc_list.append(np.log10(flux_est))\n",
    "    bkg_loc_list.append(bkg)\n",
    "    bkg_scale_list.append(bkg_sigma)\n",
    "\n",
    "sci_stack = jnp.array(np.stack(sci_list), dtype=jnp.float64)\n",
    "err_stack = jnp.array(np.stack(err_list), dtype=jnp.float64)\n",
    "flux_loc = jnp.array(np.array(flux_loc_list), dtype=jnp.float64)\n",
    "bkg_loc = jnp.array(np.array(bkg_loc_list), dtype=jnp.float64)\n",
    "bkg_scale = jnp.array(np.array(bkg_scale_list), dtype=jnp.float64)\n",
    "\n",
    "n_star, ny, nx = sci_stack.shape\n",
    "pixel_grid, xgrid, ygrid, x_axis, y_axis, extent, nx_grid, ny_grid = get_pixel_grid(np.zeros((ny, nx)), PIX_SCALE)\n",
    "\n",
    "print(\"data shape:\", sci_stack.shape)\n",
    "print(\"first 5 log10(flux) loc:\", np.array(flux_loc[:5]))\n",
    "print(\"first 5 bkg loc:\", np.array(bkg_loc[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d306e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Load STPSF base and define render helpers\n",
    "# -----------------------------\n",
    "with fits.open(BASE_PSF_PATH, memmap=True) as hdul:\n",
    "    if BASE_PSF_EXT in hdul:\n",
    "        base_psf_ss_np = np.array(hdul[BASE_PSF_EXT].data, dtype=np.float64)\n",
    "    else:\n",
    "        base_psf_ss_np = np.array(hdul[0].data, dtype=np.float64)\n",
    "\n",
    "if base_psf_ss_np.ndim != 2 or base_psf_ss_np.shape[0] != base_psf_ss_np.shape[1]:\n",
    "    raise ValueError(f\"Base PSF must be square 2D, got {base_psf_ss_np.shape}\")\n",
    "\n",
    "if base_psf_ss_np.shape[0] % SS_FACTOR != 0:\n",
    "    raise ValueError(f\"Base PSF size {base_psf_ss_np.shape[0]} not divisible by SS_FACTOR={SS_FACTOR}\")\n",
    "\n",
    "\n",
    "def normalize_kernel(kernel):\n",
    "    kernel = jnp.nan_to_num(kernel, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    kernel = jnp.clip(kernel, 0.0, jnp.inf)\n",
    "    total = jnp.sum(kernel)\n",
    "    return jnp.where(total > 0.0, kernel / total, kernel)\n",
    "\n",
    "\n",
    "def downsample_mean(kernel_ss, factor=2):\n",
    "    ny_ss, nx_ss = kernel_ss.shape\n",
    "    return kernel_ss.reshape(ny_ss // factor, factor, nx_ss // factor, factor).mean(axis=(1, 3))\n",
    "\n",
    "\n",
    "point_source_model = PointSourceModel([\"IMAGE_POSITIONS\"])\n",
    "\n",
    "\n",
    "def render_point_sources_from_kernel(kernel_det, theta_x, theta_y, amplitude):\n",
    "    theta_x = jnp.atleast_1d(theta_x)\n",
    "    theta_y = jnp.atleast_1d(theta_y)\n",
    "    amplitude = jnp.atleast_1d(amplitude)\n",
    "\n",
    "    x_pix, y_pix = pixel_grid.map_coord2pix(theta_x, theta_y)\n",
    "    kernel_t = kernel_det.T\n",
    "\n",
    "    nx_det, ny_det = pixel_grid.num_pixel_axes\n",
    "    xrange = jnp.arange(nx_det) + kernel_t.shape[0] // 2\n",
    "    yrange = jnp.arange(ny_det) + kernel_t.shape[1] // 2\n",
    "\n",
    "    result = jnp.zeros((nx_det, ny_det), dtype=kernel_det.dtype)\n",
    "    for x0, y0, amp in zip(x_pix, y_pix, amplitude):\n",
    "        xy_grid = jnp.meshgrid(xrange - x0, yrange - y0)\n",
    "        result = result + amp * map_coordinates(kernel_t, xy_grid, order=1, mode=\"nearest\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def render_single_star(kernel_det, x_pos, y_pos, flux, background):\n",
    "    kwargs_point_source = [{\"ra\": x_pos, \"dec\": y_pos, \"amp\": flux}]\n",
    "    theta_x_list, theta_y_list, amp_list = point_source_model.get_multiple_images(\n",
    "        kwargs_point_source,\n",
    "        kwargs_lens=None,\n",
    "        kwargs_solver=None,\n",
    "        k=0,\n",
    "        with_amplitude=True,\n",
    "        zero_amp_duplicates=False,\n",
    "    )\n",
    "    image = render_point_sources_from_kernel(kernel_det, theta_x_list[0], theta_y_list[0], amp_list[0])\n",
    "    return image + background\n",
    "\n",
    "\n",
    "base_psf_ss = normalize_kernel(jnp.array(base_psf_ss_np, dtype=jnp.float64))\n",
    "base_psf_det = normalize_kernel(downsample_mean(base_psf_ss, factor=SS_FACTOR))\n",
    "k_grid_ss = K_grid(base_psf_ss.shape)\n",
    "k_values_ss = jnp.array(k_grid_ss.k, dtype=jnp.float64)\n",
    "\n",
    "print(\"base ss shape:\", base_psf_ss.shape)\n",
    "print(\"base det shape:\", base_psf_det.shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(np.array(base_psf_ss), origin=\"lower\", norm=\"log\")\n",
    "axes[0].set_title(\"Base STPSF (ss grid)\")\n",
    "axes[1].imshow(np.array(base_psf_det), origin=\"lower\", norm=\"log\")\n",
    "axes[1].set_title(\"Base STPSF (detector grid)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Model: STPSF + (Matern + WN Fourier correction) + resize + per-star nuisance\n",
    "# Flux is solved analytically per star (weighted least squares), not sampled.\n",
    "# Correction field is projected to have zero 0th/1st moments (no total-flux or centroid drift).\n",
    "# -----------------------------\n",
    "def weighted_ls_flux(unit_model_stack, data_minus_bkg, err_stack, eps=1e-12):\n",
    "    inv_var = 1.0 / (err_stack**2 + eps)\n",
    "    numer = jnp.sum(unit_model_stack * data_minus_bkg * inv_var, axis=(1, 2))\n",
    "    denom = jnp.sum((unit_model_stack**2) * inv_var, axis=(1, 2)) + eps\n",
    "    flux = numer / denom\n",
    "    # enforce physically positive point-source flux\n",
    "    return jnp.clip(flux, eps, jnp.inf)\n",
    "\n",
    "\n",
    "def project_zero_moments(corr, eps=1e-12):\n",
    "    ny, nx = corr.shape\n",
    "    yy, xx = jnp.indices((ny, nx), dtype=corr.dtype)\n",
    "    xx = xx - (nx - 1) / 2.0\n",
    "    yy = yy - (ny - 1) / 2.0\n",
    "\n",
    "    b0 = jnp.ones_like(corr)\n",
    "    bx = xx\n",
    "    by = yy\n",
    "\n",
    "    d = corr.reshape(-1)\n",
    "    B = jnp.stack([b0.reshape(-1), bx.reshape(-1), by.reshape(-1)], axis=1)  # (N, 3)\n",
    "\n",
    "    BtB = B.T @ B\n",
    "    Btd = B.T @ d\n",
    "    coeff = jnp.linalg.solve(BtB + eps * jnp.eye(3, dtype=corr.dtype), Btd)\n",
    "    d_proj = d - B @ coeff\n",
    "    return d_proj.reshape(ny, nx)\n",
    "\n",
    "\n",
    "def model_psf_svi(sci_data, err_data, flux_loc, bkg_loc, bkg_scale, base_psf_ss, k_values):\n",
    "    _ = flux_loc  # kept for function interface compatibility\n",
    "\n",
    "    corr_dict = matern_power_spectrum(\n",
    "        \"PSF correction\",\n",
    "        \"psf_corr\",\n",
    "        k_values,\n",
    "        n_value=None,\n",
    "        positive=False,\n",
    "    )\n",
    "    corr_ss_raw = corr_dict[\"pixels\"]\n",
    "    corr_ss = project_zero_moments(corr_ss_raw)\n",
    "    numpyro.deterministic(\"pixels_psf_corr_proj\", corr_ss)\n",
    "\n",
    "    psf_ss_raw = base_psf_ss + corr_ss\n",
    "    psf_ss_pos = jax.nn.softplus(100.0 * psf_ss_raw) / 100.0\n",
    "    psf_ss_model = psf_ss_pos / jnp.sum(psf_ss_pos)\n",
    "    numpyro.deterministic(\"psf_ss_model\", psf_ss_model)\n",
    "\n",
    "    psf_det_model = downsample_mean(psf_ss_model, factor=SS_FACTOR)\n",
    "    psf_det_model = psf_det_model / jnp.sum(psf_det_model)\n",
    "    numpyro.deterministic(\"psf_det_model\", psf_det_model)\n",
    "\n",
    "    base_det = downsample_mean(base_psf_ss, factor=SS_FACTOR)\n",
    "    base_det = base_det / jnp.sum(base_det)\n",
    "    numpyro.deterministic(\"psf_corr_ss_eff\", psf_ss_model - base_psf_ss)\n",
    "    numpyro.deterministic(\"psf_corr_det_eff\", psf_det_model - base_det)\n",
    "\n",
    "    n_star = sci_data.shape[0]\n",
    "    with numpyro.plate(\"stars\", n_star):\n",
    "        x_pos = numpyro.sample(\n",
    "            \"x_pos\",\n",
    "            dist.TruncatedNormal(\n",
    "                loc=jnp.zeros(n_star),\n",
    "                scale=XPOS_PRIOR_SIGMA,\n",
    "                low=XPOS_BOUNDS[0],\n",
    "                high=XPOS_BOUNDS[1],\n",
    "            ),\n",
    "        )\n",
    "        y_pos = numpyro.sample(\n",
    "            \"y_pos\",\n",
    "            dist.TruncatedNormal(\n",
    "                loc=jnp.zeros(n_star),\n",
    "                scale=YPOS_PRIOR_SIGMA,\n",
    "                low=YPOS_BOUNDS[0],\n",
    "                high=YPOS_BOUNDS[1],\n",
    "            ),\n",
    "        )\n",
    "        background = numpyro.sample(\n",
    "            \"background\",\n",
    "            dist.Normal(loc=bkg_loc, scale=bkg_scale),\n",
    "        )\n",
    "\n",
    "    # Render unit-flux stars on detector grid; solve amplitudes analytically\n",
    "    unit_model_stack = jax.vmap(render_single_star, in_axes=(None, 0, 0, 0, 0))(\n",
    "        psf_det_model,\n",
    "        x_pos,\n",
    "        y_pos,\n",
    "        jnp.ones_like(x_pos),\n",
    "        jnp.zeros_like(background),\n",
    "    )\n",
    "    data_minus_bkg = sci_data - background[:, None, None]\n",
    "    flux_opt = weighted_ls_flux(unit_model_stack, data_minus_bkg, err_data)\n",
    "    numpyro.deterministic(\"flux_opt\", flux_opt)\n",
    "    numpyro.deterministic(\"log10_flux_opt\", jnp.log10(flux_opt))\n",
    "\n",
    "    model_stack = unit_model_stack * flux_opt[:, None, None] + background[:, None, None]\n",
    "    numpyro.sample(\"obs\", dist.Normal(model_stack, err_data), obs=sci_data)\n",
    "\n",
    "\n",
    "rng_key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "init_fun = infer.init_to_median(num_samples=15)\n",
    "guide = autoguide.AutoDiagonalNormal(model_psf_svi, init_loc_fn=init_fun, init_scale=0.02)\n",
    "\n",
    "scheduler = split_scheduler(MAX_ITERATIONS, init_value=0.01, transition_steps=[200, 20])\n",
    "optim = optax.adabelief(learning_rate=scheduler)\n",
    "loss = infer.TraceMeanField_ELBO()\n",
    "\n",
    "svi = SVI_vec(model_psf_svi, guide, optim, loss)\n",
    "\n",
    "svi_results = svi.run(\n",
    "    rng_key,\n",
    "    NUM_CHAINS,\n",
    "    MAX_ITERATIONS,\n",
    "    sci_stack,\n",
    "    err_stack,\n",
    "    flux_loc,\n",
    "    bkg_loc,\n",
    "    bkg_scale,\n",
    "    base_psf_ss,\n",
    "    k_values_ss,\n",
    "    stable_update=True,\n",
    ")\n",
    "\n",
    "losses_np = np.array(jax.device_get(svi_results.losses))\n",
    "final_losses = losses_np[:, -1]\n",
    "best_chain = int(np.argmin(final_losses))\n",
    "print(\"Final losses:\", final_losses)\n",
    "print(\"Best chain:\", best_chain)\n",
    "\n",
    "params_best = jax.tree.map(lambda v: v[best_chain], svi_results.params)\n",
    "median_best = guide.median(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Posterior samples and required posteriors\n",
    "# - pixel grid posterior: pixels_psf_corr (raw) and pixels_psf_corr_proj (projected)\n",
    "# - power-spectrum posterior: n_psf_corr, rho_psf_corr (and sigma_psf_corr)\n",
    "# - deterministic model PSF images for direct posterior median (SVI)\n",
    "# -----------------------------\n",
    "rng_key, sample_key, pred_key = jax.random.split(rng_key, 3)\n",
    "\n",
    "posterior_latent = guide.sample_posterior(\n",
    "    sample_key,\n",
    "    params_best,\n",
    "    sample_shape=(NUM_POST_SAMPLES,),\n",
    ")\n",
    "\n",
    "return_sites = [\n",
    "    \"psf_ss_model\",\n",
    "    \"psf_det_model\",\n",
    "    \"pixels_psf_corr\",\n",
    "    \"pixels_psf_corr_proj\",\n",
    "    \"psf_corr_ss_eff\",\n",
    "    \"psf_corr_det_eff\",\n",
    "    \"n_psf_corr\",\n",
    "    \"rho_psf_corr\",\n",
    "    \"sigma_psf_corr\",\n",
    "    \"x_pos\",\n",
    "    \"y_pos\",\n",
    "    \"background\",\n",
    "    \"flux_opt\",\n",
    "    \"log10_flux_opt\",\n",
    "]\n",
    "\n",
    "predictive = infer.Predictive(\n",
    "    model_psf_svi,\n",
    "    posterior_samples=posterior_latent,\n",
    "    return_sites=return_sites,\n",
    ")\n",
    "\n",
    "posterior = predictive(\n",
    "    pred_key,\n",
    "    sci_stack,\n",
    "    err_stack,\n",
    "    flux_loc,\n",
    "    bkg_loc,\n",
    "    bkg_scale,\n",
    "    base_psf_ss,\n",
    "    k_values_ss,\n",
    ")\n",
    "\n",
    "n_post = np.array(jax.device_get(posterior[\"n_psf_corr\"]))[:, 0]\n",
    "rho_post = np.array(jax.device_get(posterior[\"rho_psf_corr\"]))[:, 0]\n",
    "sigma_post = np.array(jax.device_get(posterior[\"sigma_psf_corr\"]))[:, 0]\n",
    "\n",
    "psf_ss_median = np.median(np.array(jax.device_get(posterior[\"psf_ss_model\"])), axis=0)\n",
    "psf_det_median = np.median(np.array(jax.device_get(posterior[\"psf_det_model\"])), axis=0)\n",
    "pixcorr_median = np.median(np.array(jax.device_get(posterior[\"pixels_psf_corr_proj\"])), axis=0)\n",
    "\n",
    "summary = {\n",
    "    \"n_median\": float(np.median(n_post)),\n",
    "    \"n_p16\": float(np.percentile(n_post, 16)),\n",
    "    \"n_p84\": float(np.percentile(n_post, 84)),\n",
    "    \"rho_median\": float(np.median(rho_post)),\n",
    "    \"rho_p16\": float(np.percentile(rho_post, 16)),\n",
    "    \"rho_p84\": float(np.percentile(rho_post, 84)),\n",
    "    \"sigma_median\": float(np.median(sigma_post)),\n",
    "    \"sigma_p16\": float(np.percentile(sigma_post, 16)),\n",
    "    \"sigma_p84\": float(np.percentile(sigma_post, 84)),\n",
    "}\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d10ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Visual diagnostics\n",
    "# -----------------------------\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "\n",
    "for i in range(losses_np.shape[0]):\n",
    "    axes[0, 0].plot(losses_np[i], alpha=0.7, label=f\"chain {i}\")\n",
    "axes[0, 0].set_yscale(\"asinh\")\n",
    "axes[0, 0].set_title(\"SVI loss\")\n",
    "axes[0, 0].legend(loc=\"best\", fontsize=8)\n",
    "\n",
    "im1 = axes[0, 1].imshow(np.array(base_psf_det), origin=\"lower\", norm=\"log\")\n",
    "axes[0, 1].set_title(\"Base STPSF (det)\")\n",
    "plt.colorbar(im1, ax=axes[0, 1], fraction=0.046, pad=0.04)\n",
    "\n",
    "im2 = axes[0, 2].imshow(psf_det_median, origin=\"lower\", norm=\"log\")\n",
    "axes[0, 2].set_title(\"Model PSF median (det)\")\n",
    "plt.colorbar(im2, ax=axes[0, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "im3 = axes[1, 0].imshow(pixcorr_median, origin=\"lower\")\n",
    "axes[1, 0].set_title(\"pixels_psf_corr median (ss)\")\n",
    "plt.colorbar(im3, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
    "\n",
    "axes[1, 1].hist(n_post, bins=30, alpha=0.8)\n",
    "axes[1, 1].set_title(\"Posterior of n_psf_corr\")\n",
    "\n",
    "axes[1, 2].hist(rho_post, bins=30, alpha=0.8)\n",
    "axes[1, 2].set_xscale(\"log\")\n",
    "axes[1, 2].set_title(\"Posterior of rho_psf_corr\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Save outputs\n",
    "# -----------------------------\n",
    "output_fits = os.path.join(OUTPUT_DIR, \"F115W_PSF_svi_stpsf_plus_corr.fits\")\n",
    "output_npz = os.path.join(OUTPUT_DIR, \"psf_svi_posterior_summary.npz\")\n",
    "\n",
    "hdr = fits.Header()\n",
    "hdr[\"NSTAR\"] = int(n_star)\n",
    "hdr[\"PIXSCALE\"] = float(PIX_SCALE)\n",
    "hdr[\"SSFACT\"] = int(SS_FACTOR)\n",
    "hdr[\"NPOST\"] = int(NUM_POST_SAMPLES)\n",
    "hdr[\"NMED\"] = float(summary[\"n_median\"])\n",
    "hdr[\"RHOMED\"] = float(summary[\"rho_median\"])\n",
    "hdr[\"SIGMED\"] = float(summary[\"sigma_median\"])\n",
    "\n",
    "hdul = fits.HDUList([\n",
    "    fits.PrimaryHDU(header=hdr),\n",
    "    fits.ImageHDU(data=np.array(psf_ss_median, dtype=np.float32), name=\"SS_PSF_MED\"),\n",
    "    fits.ImageHDU(data=np.array(psf_det_median, dtype=np.float32), name=\"DET_PSF_MED\"),\n",
    "    fits.ImageHDU(data=np.array(pixcorr_median, dtype=np.float32), name=\"SS_CORR_MED\"),\n",
    "    fits.ImageHDU(data=np.array(k_values_ss, dtype=np.float32), name=\"K_GRID\"),\n",
    "])\n",
    "hdul.writeto(output_fits, overwrite=True)\n",
    "\n",
    "np.savez(\n",
    "    output_npz,\n",
    "    n_post=n_post,\n",
    "    rho_post=rho_post,\n",
    "    sigma_post=sigma_post,\n",
    "    x_pos_post=np.array(jax.device_get(posterior[\"x_pos\"])),\n",
    "    y_pos_post=np.array(jax.device_get(posterior[\"y_pos\"])),\n",
    "    flux_opt_post=np.array(jax.device_get(posterior[\"flux_opt\"])),\n",
    "log10_flux_opt_post=np.array(jax.device_get(posterior[\"log10_flux_opt\"])),\n",
    "    background_post=np.array(jax.device_get(posterior[\"background\"])),\n",
    ")\n",
    "\n",
    "print(\"saved:\", output_fits)\n",
    "print(\"saved:\", output_npz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Result display requested:\n",
    "# - STPSF psf and modeled psf\n",
    "# - global correction field\n",
    "# - all stars: star, model, residual\n",
    "# -----------------------------\n",
    "x_med = np.median(np.array(jax.device_get(posterior[\"x_pos\"])), axis=0)\n",
    "y_med = np.median(np.array(jax.device_get(posterior[\"y_pos\"])), axis=0)\n",
    "flux_med = np.median(np.array(jax.device_get(posterior[\"flux_opt\"])), axis=0)\n",
    "bkg_med = np.median(np.array(jax.device_get(posterior[\"background\"])), axis=0)\n",
    "\n",
    "\n",
    "# Model PSF-only image for each star (background fixed to 0)\n",
    "psf_only_med = jax.vmap(render_single_star, in_axes=(None, 0, 0, 0, 0))(\n",
    "    jnp.array(psf_det_median),\n",
    "    jnp.array(x_med),\n",
    "    jnp.array(y_med),\n",
    "    jnp.array(flux_med),\n",
    "    jnp.zeros_like(jnp.array(bkg_med)),\n",
    ")\n",
    "psf_only_med = np.array(jax.device_get(psf_only_med))\n",
    "\n",
    "data_np = np.array(jax.device_get(sci_stack))\n",
    "err_np = np.array(jax.device_get(err_stack))\n",
    "bkg_cube = bkg_med[:, None, None]\n",
    "\n",
    "star_img = data_np - bkg_cube\n",
    "residual = (data_np - psf_only_med - bkg_cube) / err_np\n",
    "\n",
    "# (A) STPSF detector PSF and model detector PSF\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n",
    "im0 = axes[0].imshow(np.array(base_psf_det), origin=\"lower\", norm=\"log\")\n",
    "axes[0].set_title(\"STPSF (detector)\")\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "im1 = axes[1].imshow(np.array(psf_det_median), origin=\"lower\", norm=\"log\")\n",
    "axes[1].set_title(\"Model PSF (detector)\")\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "\n",
    "# (B) Global correction field (single field, not per-star)\n",
    "global_corr_ss = np.array(psf_ss_median) - np.array(base_psf_ss)\n",
    "global_corr_det = np.array(psf_det_median) - np.array(base_psf_det)\n",
    "\n",
    "abs_corr_ss = np.max(np.abs(global_corr_ss))\n",
    "if abs_corr_ss <= 0:\n",
    "    abs_corr_ss = 1.0\n",
    "abs_corr_det = np.max(np.abs(global_corr_det))\n",
    "if abs_corr_det <= 0:\n",
    "    abs_corr_det = 1.0\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "im2 = axes[0].imshow(global_corr_ss, origin=\"lower\", cmap=\"coolwarm\", vmin=-abs_corr_ss, vmax=abs_corr_ss)\n",
    "axes[0].set_title(\"Global correction field (SS)\")\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "plt.colorbar(im2, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "im3 = axes[1].imshow(global_corr_det, origin=\"lower\", cmap=\"coolwarm\", vmin=-abs_corr_det, vmax=abs_corr_det)\n",
    "axes[1].set_title(\"Global correction field (detector)\")\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "plt.colorbar(im3, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "\n",
    "# (C) Show all stars with 3 panels each: star / model / residual\n",
    "n_show = star_img.shape[0]\n",
    "chunk_size = 7  # rows per figure\n",
    "\n",
    "star_vmin, star_vmax = np.percentile(star_img, [1.0, 99.5])\n",
    "model_vmin, model_vmax = np.percentile(psf_only_med, [1.0, 99.5])\n",
    "\n",
    "for start in range(0, n_show, chunk_size):\n",
    "    stop = min(start + chunk_size, n_show)\n",
    "    nrows = stop - start\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, 3, figsize=(9.5, 2.6 * nrows), constrained_layout=True)\n",
    "    axes = np.array(axes)\n",
    "    if nrows == 1:\n",
    "        axes = axes[None, :]\n",
    "\n",
    "    for r, i in enumerate(range(start, stop)):\n",
    "        im_star = axes[r, 0].imshow(star_img[i], origin=\"lower\", cmap=\"viridis\", vmin=star_vmin, vmax=star_vmax)\n",
    "        axes[r, 0].set_title(f\"star {i}: data-bkg\", fontsize=9)\n",
    "\n",
    "        im_model = axes[r, 1].imshow(psf_only_med[i], origin=\"lower\", cmap=\"viridis\", vmin=model_vmin, vmax=model_vmax)\n",
    "        axes[r, 1].set_title(\"model\", fontsize=9)\n",
    "\n",
    "        im_res = axes[r, 2].imshow(residual[i], origin=\"lower\", cmap=\"bwr\", vmin=-3, vmax=3)\n",
    "        axes[r, 2].set_title(\"residual\", fontsize=9)\n",
    "\n",
    "        for c in range(3):\n",
    "            axes[r, c].set_xticks([])\n",
    "            axes[r, c].set_yticks([])\n",
    "\n",
    "    fig.colorbar(im_star, ax=axes[:, 0].tolist(), fraction=0.02, pad=0.01)\n",
    "    fig.colorbar(im_model, ax=axes[:, 1].tolist(), fraction=0.02, pad=0.01)\n",
    "    fig.colorbar(im_res, ax=axes[:, 2].tolist(), fraction=0.02, pad=0.01)\n",
    "\n",
    "    fig.suptitle(f\"Stars {start} - {stop-1}: star / model / residual\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e108fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# HMC continuation from SVI (sample full PSF + star nuisance parameter set)\n",
    "# Debug version: step-by-step logging to locate kernel crash.\n",
    "# -----------------------------\n",
    "import time\n",
    "\n",
    "def _hlog(msg):\n",
    "    print(f\"[HMC-DEBUG {time.strftime('%H:%M:%S')}] {msg}\", flush=True)\n",
    "\n",
    "_hlog(\"Step 0: configure HMC hyperparameters\")\n",
    "HMC_WARMUP = 500\n",
    "HMC_SAMPLES = 1500\n",
    "HMC_CHAINS = 4\n",
    "HMC_TARGET_ACCEPT = 0.9\n",
    "HMC_CHAIN_METHOD = \"vectorized\"  # use vectorized chains for GPU execution\n",
    "\n",
    "_hlog(f\"Step 0.1: devices={jax.devices()}\")\n",
    "_hlog(f\"Step 0.2: sci_stack={tuple(sci_stack.shape)}, err_stack={tuple(err_stack.shape)}, base_psf_ss={tuple(base_psf_ss.shape)}\")\n",
    "_hlog(f\"Step 0.3: finite checks: sci={bool(np.array(jnp.all(jnp.isfinite(sci_stack))))}, err={bool(np.array(jnp.all(jnp.isfinite(err_stack))))}, k={bool(np.array(jnp.all(jnp.isfinite(k_values_ss))))}\")\n",
    "\n",
    "_hlog(\"Step 1: build per-SVI-chain medians for initialization\")\n",
    "svi_chain_medians = []\n",
    "for ic in range(NUM_CHAINS):\n",
    "    _hlog(f\"Step 1.{ic+1}: median from SVI chain {ic}\")\n",
    "    params_ic = jax.tree.map(lambda v: v[ic], svi_results.params)\n",
    "    median_ic = guide.median(params_ic)\n",
    "    svi_chain_medians.append(median_ic)\n",
    "_hlog(\"Step 1 done\")\n",
    "\n",
    "if HMC_CHAINS > len(svi_chain_medians):\n",
    "    raise ValueError(f\"HMC_CHAINS={HMC_CHAINS} > available SVI chains={len(svi_chain_medians)}\")\n",
    "\n",
    "# Full set requested: pixels_wn_psf_corr + all 29 star nuisances + n/rho/sigma\n",
    "HMC_SAMPLE_SITES = (\n",
    "    \"n_psf_corr\",\n",
    "    \"rho_psf_corr\",\n",
    "    \"sigma_psf_corr\",\n",
    "    \"pixels_wn_psf_corr\",\n",
    "    \"x_pos\",\n",
    "    \"y_pos\",\n",
    "    \"background\",\n",
    ")\n",
    "\n",
    "_hlog(\"Step 2: validate required sites\")\n",
    "for k in HMC_SAMPLE_SITES:\n",
    "    if k not in svi_chain_medians[0]:\n",
    "        raise KeyError(f\"Missing site in SVI median for HMC init: {k}\")\n",
    "_hlog(\"Step 2 done\")\n",
    "\n",
    "_hlog(\"Step 3: build init_params_hmc\")\n",
    "init_params_hmc = {\n",
    "    k: jnp.stack([jnp.array(svi_chain_medians[i][k]) for i in range(HMC_CHAINS)], axis=0)\n",
    "    for k in HMC_SAMPLE_SITES\n",
    "}\n",
    "for k in HMC_SAMPLE_SITES:\n",
    "    arr = init_params_hmc[k]\n",
    "    _hlog(f\"  init[{k}] shape={tuple(arr.shape)} dtype={arr.dtype}\")\n",
    "\n",
    "_hlog(\"Step 3.1: block_until_ready on init params\")\n",
    "_ = jax.tree.map(lambda x: x.block_until_ready() if hasattr(x, \"block_until_ready\") else x, init_params_hmc)\n",
    "_hlog(\"Step 3.1 done\")\n",
    "\n",
    "_hlog(\"Step 4: create NUTS kernel\")\n",
    "model_hmc = model_psf_svi\n",
    "nuts_kernel = infer.NUTS(model_hmc, target_accept_prob=HMC_TARGET_ACCEPT)\n",
    "_hlog(\"Step 4 done\")\n",
    "\n",
    "_hlog(\"Step 5: create MCMC object\")\n",
    "mcmc_hmc = infer.MCMC(\n",
    "    nuts_kernel,\n",
    "    num_warmup=HMC_WARMUP,\n",
    "    num_samples=HMC_SAMPLES,\n",
    "    num_chains=HMC_CHAINS,\n",
    "    chain_method=HMC_CHAIN_METHOD,\n",
    "    progress_bar=True,\n",
    ")\n",
    "_hlog(\"Step 5 done\")\n",
    "\n",
    "_hlog(\"Step 6: split rng and start mcmc_hmc.run\")\n",
    "rng_key, hmc_key = jax.random.split(rng_key)\n",
    "_hlog(f\"Step 6.1: hmc_key shape={tuple(hmc_key.shape)}\")\n",
    "\n",
    "try:\n",
    "    mcmc_hmc.run(\n",
    "        hmc_key,\n",
    "        sci_stack,\n",
    "        err_stack,\n",
    "        flux_loc,\n",
    "        bkg_loc,\n",
    "        bkg_scale,\n",
    "        base_psf_ss,\n",
    "        k_values_ss,\n",
    "        init_params=init_params_hmc,\n",
    "    )\n",
    "    _hlog(\"Step 6 done: mcmc_hmc.run finished\")\n",
    "except Exception as e:\n",
    "    _hlog(f\"Step 6 FAILED: {type(e).__name__}: {e}\")\n",
    "    raise\n",
    "\n",
    "# For large high-dimensional posteriors, avoid az.from_numpyro() heavy conversion.\n",
    "_hlog(\"Step 7: get raw posterior samples\")\n",
    "hmc_samples = mcmc_hmc.get_samples(group_by_chain=True)\n",
    "for k in [\"n_psf_corr\", \"rho_psf_corr\", \"sigma_psf_corr\", \"pixels_wn_psf_corr\", \"x_pos\", \"y_pos\", \"background\", \"psf_det_model\", \"psf_ss_model\", \"flux_opt\"]:\n",
    "    if k in hmc_samples:\n",
    "        _hlog(f\"  hmc_samples[{k}] shape={tuple(np.array(hmc_samples[k]).shape)}\")\n",
    "_hlog(\"Step 7 done\")\n",
    "\n",
    "_hlog(\"Step 8: build lightweight ArviZ idata for trace only\")\n",
    "def _trace_2d(arr):\n",
    "    arr = np.array(jax.device_get(arr))\n",
    "    while arr.ndim > 2 and arr.shape[-1] == 1:\n",
    "        arr = arr[..., 0]\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(f\"Trace array expected 2D after squeeze, got {arr.shape}\")\n",
    "    return arr\n",
    "\n",
    "n_trace = _trace_2d(hmc_samples[\"n_psf_corr\"])\n",
    "rho_trace = _trace_2d(hmc_samples[\"rho_psf_corr\"])\n",
    "sigma_trace = _trace_2d(hmc_samples[\"sigma_psf_corr\"])\n",
    "\n",
    "inf_data_hmc = az.from_dict(\n",
    "    posterior={\n",
    "        \"n_psf_corr\": n_trace,\n",
    "        \"rho_psf_corr\": rho_trace,\n",
    "        \"sigma_psf_corr\": sigma_trace,\n",
    "    }\n",
    ")\n",
    "_hlog(\"Step 8 done\")\n",
    "\n",
    "_hlog(\"Step 9: save HMC outputs to result/\")\n",
    "hmc_trace_npz = os.path.join(OUTPUT_DIR, \"hmc_trace_n_rho_sigma.npz\")\n",
    "np.savez(hmc_trace_npz, n_trace=n_trace, rho_trace=rho_trace, sigma_trace=sigma_trace)\n",
    "\n",
    "psf_ss_hmc_median = np.median(np.array(jax.device_get(hmc_samples[\"psf_ss_model\"])), axis=(0, 1))\n",
    "psf_det_hmc_median = np.median(np.array(jax.device_get(hmc_samples[\"psf_det_model\"])), axis=(0, 1))\n",
    "psf_ss_hmc_p16 = np.percentile(np.array(jax.device_get(hmc_samples[\"psf_ss_model\"])), 16, axis=(0, 1))\n",
    "psf_ss_hmc_p84 = np.percentile(np.array(jax.device_get(hmc_samples[\"psf_ss_model\"])), 84, axis=(0, 1))\n",
    "\n",
    "hmc_fits_path = os.path.join(OUTPUT_DIR, \"F115W_PSF_hmc_median.fits\")\n",
    "fits.HDUList([\n",
    "    fits.PrimaryHDU(),\n",
    "    fits.ImageHDU(data=np.array(psf_ss_hmc_median, dtype=np.float32), name=\"SS_PSF_HMC_MED\"),\n",
    "    fits.ImageHDU(data=np.array(psf_det_hmc_median, dtype=np.float32), name=\"DET_PSF_HMC_MED\"),\n",
    "    fits.ImageHDU(data=np.array(psf_ss_hmc_p16, dtype=np.float32), name=\"SS_PSF_HMC_P16\"),\n",
    "    fits.ImageHDU(data=np.array(psf_ss_hmc_p84, dtype=np.float32), name=\"SS_PSF_HMC_P84\"),\n",
    "]).writeto(hmc_fits_path, overwrite=True)\n",
    "\n",
    "_hlog(f\"Step 9 done: saved {hmc_trace_npz}\")\n",
    "_hlog(f\"Step 9 done: saved {hmc_fits_path}\")\n",
    "\n",
    "_hlog(\"Step 10: print summary\")\n",
    "print(mcmc_hmc.print_summary())\n",
    "_hlog(\"Step 10 done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# HMC traces for n / rho / sigma (4 chains) via ArviZ (lightweight idata)\n",
    "# -----------------------------\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "chains_to_plot = np.arange(HMC_CHAINS)\n",
    "_ = az.plot_trace(\n",
    "    inf_data_hmc.sel(chain=chains_to_plot),\n",
    "    var_names=[\"n_psf_corr\", \"rho_psf_corr\", \"sigma_psf_corr\"],\n",
    "    figsize=(10, 8),\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792620a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Compare star0: 4 chain-median models/residuals + median over 4 chains\n",
    "# Use deterministic outputs directly from HMC samples.\n",
    "# -----------------------------\n",
    "# chain-wise medians for sampled parameters\n",
    "hmc_chain_median = jax.tree.map(lambda v: jnp.median(v, axis=1), hmc_samples)\n",
    "\n",
    "# chain-wise medians of deterministic PSF image and solved flux\n",
    "psf_det_chain_median = np.median(np.array(jax.device_get(hmc_samples[\"psf_det_model\"])), axis=1)\n",
    "flux_opt_chain_median = np.median(np.array(jax.device_get(hmc_samples[\"flux_opt\"])), axis=1)\n",
    "\n",
    "star0_data = np.array(jax.device_get(sci_stack))[0]\n",
    "star0_err = np.array(jax.device_get(err_stack))[0]\n",
    "\n",
    "chain_models = []\n",
    "chain_residuals = []\n",
    "for c in range(HMC_CHAINS):\n",
    "    psf_det_c = psf_det_chain_median[c]\n",
    "\n",
    "    x0 = float(np.array(jax.device_get(hmc_chain_median[\"x_pos\"][c]))[0])\n",
    "    y0 = float(np.array(jax.device_get(hmc_chain_median[\"y_pos\"][c]))[0])\n",
    "    bkg0 = float(np.array(jax.device_get(hmc_chain_median[\"background\"][c]))[0])\n",
    "    flux0 = float(flux_opt_chain_median[c][0])\n",
    "\n",
    "    model0_c = np.array(jax.device_get(render_single_star(jnp.array(psf_det_c), x0, y0, flux0, 0.0)))\n",
    "    resid0_c = (star0_data - model0_c - bkg0) / star0_err\n",
    "\n",
    "    chain_models.append(model0_c)\n",
    "    chain_residuals.append(resid0_c)\n",
    "\n",
    "chain_models = np.array(chain_models)\n",
    "chain_residuals = np.array(chain_residuals)\n",
    "\n",
    "# plot 4 chain models and residuals\n",
    "fig, axes = plt.subplots(2, HMC_CHAINS, figsize=(3.0 * HMC_CHAINS, 6), constrained_layout=True)\n",
    "model_vmin, model_vmax = np.percentile(chain_models, [1.0, 99.5])\n",
    "for c in range(HMC_CHAINS):\n",
    "    im_m = axes[0, c].imshow(chain_models[c], origin=\"lower\", cmap=\"viridis\", vmin=model_vmin, vmax=model_vmax)\n",
    "    axes[0, c].set_title(f\"chain {c} model\")\n",
    "    im_r = axes[1, c].imshow(chain_residuals[c], origin=\"lower\", cmap=\"bwr\", vmin=-3, vmax=3)\n",
    "    axes[1, c].set_title(f\"chain {c} residual\")\n",
    "    axes[0, c].set_xticks([]); axes[0, c].set_yticks([])\n",
    "    axes[1, c].set_xticks([]); axes[1, c].set_yticks([])\n",
    "fig.colorbar(im_m, ax=axes[0, :].tolist(), fraction=0.02, pad=0.01)\n",
    "fig.colorbar(im_r, ax=axes[1, :].tolist(), fraction=0.02, pad=0.01)\n",
    "\n",
    "# median model/residual over the 4 chain medians\n",
    "model0_median4 = np.median(chain_models, axis=0)\n",
    "bkg0_median4 = np.median([\n",
    "    float(np.array(jax.device_get(hmc_chain_median[\"background\"][c]))[0]) for c in range(HMC_CHAINS)\n",
    "])\n",
    "resid0_median4 = (star0_data - model0_median4 - bkg0_median4) / star0_err\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4), constrained_layout=True)\n",
    "im_a = axes[0].imshow(model0_median4, origin=\"lower\", cmap=\"viridis\", vmin=model_vmin, vmax=model_vmax)\n",
    "axes[0].set_title(\"star0 model (median of 4 chains)\")\n",
    "im_b = axes[1].imshow(resid0_median4, origin=\"lower\", cmap=\"bwr\", vmin=-3, vmax=3)\n",
    "axes[1].set_title(\"star0 residual (median of 4 chains)\")\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.colorbar(im_a, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "fig.colorbar(im_b, ax=axes[1], fraction=0.046, pad=0.04)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
