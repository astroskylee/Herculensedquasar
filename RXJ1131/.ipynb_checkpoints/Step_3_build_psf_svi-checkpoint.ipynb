{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fecfe9",
   "metadata": {},
   "source": [
    "# Step 3: Build PSF Model with SVI (mask-aware)\n",
    "\n",
    "这个 notebook 使用 `Herculens_Tian_JWST.ipynb` 同款的 SVI 思路，\n",
    "对 29 个 `psf_data/*SCIERR.fits` 联合建模。\n",
    "\n",
    "建模结构：\n",
    "- `PSF_model_ss = STPSF_base_ss + correction_ss`\n",
    "- `correction_ss` 来自 `matern_power_spectrum + white-noise Fourier modes`\n",
    "- 在 supersampled 网格建模后，`resize` 到 detector 101x101\n",
    "- 每个观测星点自由度：`x_pos, y_pos, log10_flux, background`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d722183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.ndimage import map_coordinates\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "import numpyro.infer as infer\n",
    "import numpyro.infer.autoguide as autoguide\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "from astropy.io import fits\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "numpyro.enable_x64()\n",
    "\n",
    "from power_spectrum_prior import P_Matern, pack_fft_values, K_grid\n",
    "from herculens.Coordinates.pixel_grid import PixelGrid\n",
    "from herculens.PointSourceModel.point_source_model import PointSourceModel\n",
    "\n",
    "\n",
    "def split_scheduler(\n",
    "    max_iterations,\n",
    "    init_value=0.1,\n",
    "    decay_rates=(0.99, 0.99),\n",
    "    transition_steps=(50, 10),\n",
    "    boundary=0.5,\n",
    "):\n",
    "    boundary = int(max_iterations * boundary)\n",
    "\n",
    "    scheduler1 = optax.exponential_decay(\n",
    "        init_value=init_value,\n",
    "        decay_rate=decay_rates[0],\n",
    "        transition_steps=transition_steps[0],\n",
    "    )\n",
    "\n",
    "    scheduler2 = optax.exponential_decay(\n",
    "        init_value=scheduler1(boundary),\n",
    "        decay_rate=decay_rates[1],\n",
    "        transition_steps=transition_steps[1],\n",
    "    )\n",
    "\n",
    "    return optax.join_schedules([scheduler1, scheduler2], boundaries=[boundary])\n",
    "\n",
    "\n",
    "class SVI_vec(numpyro.infer.SVI):\n",
    "    def run(\n",
    "        self,\n",
    "        rng_key,\n",
    "        num_chains,\n",
    "        num_steps,\n",
    "        *args,\n",
    "        stable_update=False,\n",
    "        forward_mode_differentiation=False,\n",
    "        init_states=None,\n",
    "        init_params=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        def body_fn(svi_state, _):\n",
    "            if stable_update:\n",
    "                svi_state, loss = self.stable_update(\n",
    "                    svi_state,\n",
    "                    *args,\n",
    "                    forward_mode_differentiation=forward_mode_differentiation,\n",
    "                    **kwargs,\n",
    "                )\n",
    "            else:\n",
    "                svi_state, loss = self.update(\n",
    "                    svi_state,\n",
    "                    *args,\n",
    "                    forward_mode_differentiation=forward_mode_differentiation,\n",
    "                    **kwargs,\n",
    "                )\n",
    "            return svi_state, loss\n",
    "\n",
    "        if init_states is None:\n",
    "            rng_keys = jax.random.split(rng_key, num_chains)\n",
    "\n",
    "            def init_one(k):\n",
    "                return self.init(k, *args, init_params=init_params, **kwargs)\n",
    "\n",
    "            svi_states = jax.vmap(init_one)(rng_keys)\n",
    "        else:\n",
    "            svi_states = init_states\n",
    "\n",
    "        def run_one_chain(state):\n",
    "            final_state, losses = jax.lax.scan(body_fn, state, jnp.arange(num_steps))\n",
    "            return final_state, losses\n",
    "\n",
    "        final_states, losses = jax.vmap(run_one_chain)(svi_states)\n",
    "        return numpyro.infer.svi.SVIRunResult(self.get_params(final_states), final_states, losses)\n",
    "\n",
    "\n",
    "def get_pixel_grid(data, pix_scale, ss=1):\n",
    "    ny, nx = data.shape\n",
    "    ny *= ss\n",
    "    nx *= ss\n",
    "    pix_scale /= ss\n",
    "    half_size_x = nx * pix_scale / 2\n",
    "    half_size_y = ny * pix_scale / 2\n",
    "    ra_at_xy_0 = -half_size_x + pix_scale / 2\n",
    "    dec_at_xy_0 = -half_size_y + pix_scale / 2\n",
    "    transform_pix2angle = pix_scale * np.eye(2)\n",
    "    kwargs_pixel = {\n",
    "        'nx': nx,\n",
    "        'ny': ny,\n",
    "        'ra_at_xy_0': ra_at_xy_0,\n",
    "        'dec_at_xy_0': dec_at_xy_0,\n",
    "        'transform_pix2angle': transform_pix2angle,\n",
    "    }\n",
    "    pixel_grid = PixelGrid(**kwargs_pixel)\n",
    "    xgrid, ygrid = pixel_grid.pixel_coordinates\n",
    "    x_axis = xgrid[0]\n",
    "    y_axis = ygrid[:, 0]\n",
    "    extent = pixel_grid.extent\n",
    "    return pixel_grid, xgrid, ygrid, x_axis, y_axis, extent, nx, ny\n",
    "\n",
    "\n",
    "def matern_power_spectrum(\n",
    "    plate_name,\n",
    "    param_name,\n",
    "    k,\n",
    "    k_zero=None,\n",
    "    n_high=100,\n",
    "    n_value=None,\n",
    "    positive=True,\n",
    "):\n",
    "    with numpyro.plate(f'{plate_name} power spectrum params - [1]', 1):\n",
    "        if n_value is None:\n",
    "            n = numpyro.sample(f'n_{param_name}', dist.LogUniform(0.3, n_high))\n",
    "        else:\n",
    "            n = numpyro.deterministic(f'n_{param_name}', jnp.atleast_1d(n_value))\n",
    "        sigma = numpyro.sample(f'sigma_{param_name}', dist.LogUniform(1e-5, 10))\n",
    "        rho = numpyro.sample(f'rho_{param_name}', dist.LogNormal(2.1, 1.1))\n",
    "\n",
    "    P = P_Matern(k, n[0], sigma[0], rho[0], k_zero=k_zero)\n",
    "    scale = jnp.sqrt(P)\n",
    "\n",
    "    ny, nx = scale.shape\n",
    "    with numpyro.plate(f'{plate_name} fft y - [{ny}]', ny):\n",
    "        with numpyro.plate(f'{plate_name} fft x - [{nx}]', nx):\n",
    "            pixels_wn = numpyro.sample(f'pixels_wn_{param_name}', dist.Normal(0, 1))\n",
    "\n",
    "    gp = jnp.fft.irfft2(pack_fft_values(pixels_wn * scale), s=scale.shape, norm='ortho')\n",
    "    if positive:\n",
    "        gp = jax.nn.softplus(100 * gp) / 100.0\n",
    "    pixels = numpyro.deterministic(f'pixels_{param_name}', gp)\n",
    "\n",
    "    return {'pixels': pixels}\n",
    "\n",
    "\n",
    "print(\"JAX devices:\", jax.devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "PIX_SCALE = 0.05\n",
    "DATA_DIR = \"../../Data/RXJ1131\"\n",
    "PSF_DATA_DIR = \"./psf_data\"\n",
    "BASE_PSF_PATH = os.path.join(DATA_DIR, \"F115W_PSF_stpsf_ss2.fits\")\n",
    "BASE_PSF_EXT = \"OVERSAMP\"   # supersampled extension in STPSF file\n",
    "OUTPUT_DIR = PSF_DATA_DIR\n",
    "\n",
    "# explicit candidate list from Step 2 selection\n",
    "SELECTED_CANDS = [4, 6, 7, 8, 15, 16, 20, 21]\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "# smoke test switch\n",
    "SMOKE_TEST = True\n",
    "SMOKE_MAX_STARS = 8\n",
    "MAX_ITERATIONS = 120 if SMOKE_TEST else 8000\n",
    "NUM_CHAINS = 1 if SMOKE_TEST else 4\n",
    "NUM_POST_SAMPLES = 40 if SMOKE_TEST else 300\n",
    "TRANSITION_STEPS = [40, 10] if SMOKE_TEST else [200, 20]\n",
    "OUTPUT_SUFFIX = \"_smoke\" if SMOKE_TEST else \"\"\n",
    "\n",
    "SS_FACTOR = 2\n",
    "\n",
    "XPOS_PRIOR_SIGMA = 0.03\n",
    "YPOS_PRIOR_SIGMA = 0.03\n",
    "XPOS_BOUNDS = (-0.30, 0.30)\n",
    "YPOS_BOUNDS = (-0.30, 0.30)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "print(\"SMOKE_TEST:\", SMOKE_TEST)\n",
    "print(\"MAX_ITERATIONS:\", MAX_ITERATIONS)\n",
    "print(\"NUM_CHAINS:\", NUM_CHAINS)\n",
    "print(\"NUM_POST_SAMPLES:\", NUM_POST_SAMPLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d81db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Load selected SCIERR cutouts (+ optional MASK)\n",
    "# -----------------------------\n",
    "psf_files = []\n",
    "for cid in SELECTED_CANDS:\n",
    "    matches = sorted(glob.glob(os.path.join(PSF_DATA_DIR, f\"C{cid:02d}_*_SCIERR.fits\")))\n",
    "    if len(matches) == 0:\n",
    "        raise FileNotFoundError(f\"Missing selected file for C{cid:02d} in {PSF_DATA_DIR}\")\n",
    "    psf_files.append(matches[0])\n",
    "\n",
    "if SMOKE_TEST and len(psf_files) > SMOKE_MAX_STARS:\n",
    "    psf_files = psf_files[:SMOKE_MAX_STARS]\n",
    "\n",
    "print(f\"Using {len(psf_files)} selected cutouts\")\n",
    "for fp in psf_files:\n",
    "    print(\" -\", os.path.basename(fp))\n",
    "\n",
    "sci_list = []\n",
    "err_list = []\n",
    "mask_list = []\n",
    "flux_loc_list = []\n",
    "bkg_loc_list = []\n",
    "bkg_scale_list = []\n",
    "mask_frac_list = []\n",
    "\n",
    "for fp in psf_files:\n",
    "    with fits.open(fp, memmap=True) as hdul:\n",
    "        sci = np.array(hdul[\"SCI\"].data, dtype=np.float64)\n",
    "        err = np.array(hdul[\"ERR\"].data, dtype=np.float64)\n",
    "\n",
    "        if \"MASK\" in hdul:\n",
    "            # convention: MASK==1 means masked pixel\n",
    "            mask_raw = np.array(hdul[\"MASK\"].data, dtype=np.uint8)\n",
    "            mask_keep = ~mask_raw.astype(bool)\n",
    "        else:\n",
    "            mask_keep = np.ones_like(sci, dtype=bool)\n",
    "\n",
    "    if sci.shape != err.shape:\n",
    "        raise ValueError(f\"Shape mismatch in {fp}: SCI{sci.shape} vs ERR{err.shape}\")\n",
    "    if mask_keep.shape != sci.shape:\n",
    "        raise ValueError(f\"MASK shape mismatch in {fp}: MASK{mask_keep.shape} vs SCI{sci.shape}\")\n",
    "\n",
    "    valid = np.isfinite(sci) & np.isfinite(err) & (err > 0)\n",
    "    fit_valid = valid & mask_keep\n",
    "    if not np.any(fit_valid):\n",
    "        raise ValueError(f\"No valid unmasked pixels in {fp}\")\n",
    "\n",
    "    med_err = float(np.nanmedian(err[fit_valid]))\n",
    "\n",
    "    sci = np.where(valid, sci, 0.0)\n",
    "    err = np.where(valid, err, med_err)\n",
    "    err = np.clip(err, med_err * 0.25, np.inf)\n",
    "    mask_keep = np.where(valid, mask_keep, False)\n",
    "\n",
    "    # robust background estimate from 5-pixel border, restricted to unmasked pixels if possible\n",
    "    border_sci = np.concatenate([\n",
    "        sci[:5, :].ravel(),\n",
    "        sci[-5:, :].ravel(),\n",
    "        sci[:, :5].ravel(),\n",
    "        sci[:, -5:].ravel(),\n",
    "    ])\n",
    "    border_msk = np.concatenate([\n",
    "        mask_keep[:5, :].ravel(),\n",
    "        mask_keep[-5:, :].ravel(),\n",
    "        mask_keep[:, :5].ravel(),\n",
    "        mask_keep[:, -5:].ravel(),\n",
    "    ])\n",
    "\n",
    "    bvals = border_sci[np.isfinite(border_sci) & border_msk]\n",
    "    if bvals.size == 0:\n",
    "        bvals = sci[fit_valid]\n",
    "\n",
    "    bkg = float(np.nanmedian(bvals))\n",
    "    mad = float(np.nanmedian(np.abs(bvals - bkg)))\n",
    "    bkg_sigma = max(1.4826 * mad, med_err * 0.1, 1e-6)\n",
    "\n",
    "    flux_est = float(np.sum(np.clip(sci - bkg, 0.0, None) * mask_keep.astype(np.float64)))\n",
    "    flux_est = max(flux_est, 1e-6)\n",
    "\n",
    "    sci_list.append(sci)\n",
    "    err_list.append(err)\n",
    "    mask_list.append(mask_keep.astype(np.float64))\n",
    "    flux_loc_list.append(np.log10(flux_est))\n",
    "    bkg_loc_list.append(bkg)\n",
    "    bkg_scale_list.append(bkg_sigma)\n",
    "    mask_frac_list.append(1.0 - float(np.mean(mask_keep)))\n",
    "\n",
    "sci_stack = jnp.array(np.stack(sci_list), dtype=jnp.float64)\n",
    "err_stack = jnp.array(np.stack(err_list), dtype=jnp.float64)\n",
    "mask_stack = jnp.array(np.stack(mask_list), dtype=jnp.float64)  # 1=use, 0=masked\n",
    "flux_loc = jnp.array(np.array(flux_loc_list), dtype=jnp.float64)\n",
    "bkg_loc = jnp.array(np.array(bkg_loc_list), dtype=jnp.float64)\n",
    "bkg_scale = jnp.array(np.array(bkg_scale_list), dtype=jnp.float64)\n",
    "\n",
    "n_star, ny, nx = sci_stack.shape\n",
    "pixel_grid, xgrid, ygrid, x_axis, y_axis, extent, nx_grid, ny_grid = get_pixel_grid(np.zeros((ny, nx)), PIX_SCALE)\n",
    "\n",
    "print(\"data shape:\", sci_stack.shape)\n",
    "print(\"mask fraction per star:\", np.array(mask_frac_list))\n",
    "print(\"first 5 log10(flux) loc:\", np.array(flux_loc[:5]))\n",
    "print(\"first 5 bkg loc:\", np.array(bkg_loc[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d306e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Build base PSF and define render helpers\n",
    "# -----------------------------\n",
    "def center_crop_or_pad_np(arr, target_shape):\n",
    "    ty, tx = target_shape\n",
    "    ay, ax = arr.shape\n",
    "\n",
    "    # crop if larger\n",
    "    if ay > ty:\n",
    "        y0 = (ay - ty) // 2\n",
    "        arr = arr[y0:y0 + ty, :]\n",
    "    if ax > tx:\n",
    "        x0 = (ax - tx) // 2\n",
    "        arr = arr[:, x0:x0 + tx]\n",
    "\n",
    "    # pad if smaller\n",
    "    ay, ax = arr.shape\n",
    "    if ay < ty or ax < tx:\n",
    "        py0 = (ty - ay) // 2\n",
    "        py1 = ty - ay - py0\n",
    "        px0 = (tx - ax) // 2\n",
    "        px1 = tx - ax - px0\n",
    "        arr = np.pad(arr, ((py0, py1), (px0, px1)), mode=\"constant\", constant_values=0.0)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def normalize_np(kernel, eps=1e-20):\n",
    "    k = np.nan_to_num(kernel, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    k = np.clip(k, 0.0, np.inf)\n",
    "    s = np.sum(k)\n",
    "    if s <= eps:\n",
    "        raise ValueError(\"Kernel normalization failed: sum<=0\")\n",
    "    return k / s\n",
    "\n",
    "\n",
    "def downsample_mean_np(kernel_ss, factor=2):\n",
    "    ny_ss, nx_ss = kernel_ss.shape\n",
    "    return kernel_ss.reshape(ny_ss // factor, factor, nx_ss // factor, factor).mean(axis=(1, 3))\n",
    "\n",
    "\n",
    "if os.path.exists(BASE_PSF_PATH):\n",
    "    with fits.open(BASE_PSF_PATH, memmap=True) as hdul:\n",
    "        if BASE_PSF_EXT in hdul:\n",
    "            base_psf_ss_np = np.array(hdul[BASE_PSF_EXT].data, dtype=np.float64)\n",
    "        else:\n",
    "            base_psf_ss_np = np.array(hdul[0].data, dtype=np.float64)\n",
    "    print(\"Loaded external base PSF:\", BASE_PSF_PATH)\n",
    "else:\n",
    "    base_psf_ss_np = None\n",
    "    print(\"[WARN] Base PSF file not found; fallback to data-driven base PSF\")\n",
    "\n",
    "if base_psf_ss_np is None:\n",
    "    # data-driven detector PSF from median unmasked positive signal\n",
    "    sci_np = np.array(jax.device_get(sci_stack))\n",
    "    msk_np = np.array(jax.device_get(mask_stack)) > 0.5\n",
    "    bkg_np = np.array(jax.device_get(bkg_loc))[:, None, None]\n",
    "\n",
    "    stars = np.clip(sci_np - bkg_np, 0.0, None)\n",
    "    stars = np.where(msk_np, stars, np.nan)\n",
    "    base_det_np = np.nanmedian(stars, axis=0)\n",
    "    base_det_np = np.nan_to_num(base_det_np, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    base_det_np = normalize_np(base_det_np)\n",
    "else:\n",
    "    if base_psf_ss_np.ndim != 2 or base_psf_ss_np.shape[0] != base_psf_ss_np.shape[1]:\n",
    "        raise ValueError(f\"Base PSF must be square 2D, got {base_psf_ss_np.shape}\")\n",
    "\n",
    "    # make supersampled shape divisible by SS_FACTOR\n",
    "    ny_ss, nx_ss = base_psf_ss_np.shape\n",
    "    ny_trim = ny_ss - (ny_ss % SS_FACTOR)\n",
    "    nx_trim = nx_ss - (nx_ss % SS_FACTOR)\n",
    "    if ny_trim != ny_ss or nx_trim != nx_ss:\n",
    "        y0 = (ny_ss - ny_trim) // 2\n",
    "        x0 = (nx_ss - nx_trim) // 2\n",
    "        base_psf_ss_np = base_psf_ss_np[y0:y0 + ny_trim, x0:x0 + nx_trim]\n",
    "        print(f\"Trimmed base SS PSF to {base_psf_ss_np.shape} for SS_FACTOR={SS_FACTOR}\")\n",
    "\n",
    "    base_psf_ss_np = normalize_np(base_psf_ss_np)\n",
    "    base_det_np = downsample_mean_np(base_psf_ss_np, factor=SS_FACTOR)\n",
    "    base_det_np = normalize_np(base_det_np)\n",
    "\n",
    "# force detector PSF size to match cutout size\n",
    "base_det_np = center_crop_or_pad_np(base_det_np, (ny, nx))\n",
    "base_det_np = normalize_np(base_det_np)\n",
    "\n",
    "# rebuild supersampled base from detector base to guarantee exact shape compatibility\n",
    "base_psf_ss_np = np.repeat(np.repeat(base_det_np, SS_FACTOR, axis=0), SS_FACTOR, axis=1)\n",
    "base_psf_ss_np = normalize_np(base_psf_ss_np)\n",
    "\n",
    "\n",
    "def normalize_kernel(kernel):\n",
    "    kernel = jnp.nan_to_num(kernel, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    kernel = jnp.clip(kernel, 0.0, jnp.inf)\n",
    "    total = jnp.sum(kernel)\n",
    "    return jnp.where(total > 0.0, kernel / total, kernel)\n",
    "\n",
    "\n",
    "def downsample_mean(kernel_ss, factor=2):\n",
    "    ny_ss, nx_ss = kernel_ss.shape\n",
    "    return kernel_ss.reshape(ny_ss // factor, factor, nx_ss // factor, factor).mean(axis=(1, 3))\n",
    "\n",
    "\n",
    "point_source_model = PointSourceModel([\"IMAGE_POSITIONS\"])\n",
    "\n",
    "\n",
    "def render_point_sources_from_kernel(kernel_det, theta_x, theta_y, amplitude):\n",
    "    theta_x = jnp.atleast_1d(theta_x)\n",
    "    theta_y = jnp.atleast_1d(theta_y)\n",
    "    amplitude = jnp.atleast_1d(amplitude)\n",
    "\n",
    "    x_pix, y_pix = pixel_grid.map_coord2pix(theta_x, theta_y)\n",
    "    kernel_t = kernel_det.T\n",
    "\n",
    "    nx_det, ny_det = pixel_grid.num_pixel_axes\n",
    "    xrange = jnp.arange(nx_det) + kernel_t.shape[0] // 2\n",
    "    yrange = jnp.arange(ny_det) + kernel_t.shape[1] // 2\n",
    "\n",
    "    result = jnp.zeros((nx_det, ny_det), dtype=kernel_det.dtype)\n",
    "    for x0, y0, amp in zip(x_pix, y_pix, amplitude):\n",
    "        xy_grid = jnp.meshgrid(xrange - x0, yrange - y0)\n",
    "        result = result + amp * map_coordinates(kernel_t, xy_grid, order=1, mode=\"nearest\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def render_single_star(kernel_det, x_pos, y_pos, flux, background):\n",
    "    kwargs_point_source = [{\"ra\": x_pos, \"dec\": y_pos, \"amp\": flux}]\n",
    "    theta_x_list, theta_y_list, amp_list = point_source_model.get_multiple_images(\n",
    "        kwargs_point_source,\n",
    "        kwargs_lens=None,\n",
    "        kwargs_solver=None,\n",
    "        k=0,\n",
    "        with_amplitude=True,\n",
    "        zero_amp_duplicates=False,\n",
    "    )\n",
    "    image = render_point_sources_from_kernel(kernel_det, theta_x_list[0], theta_y_list[0], amp_list[0])\n",
    "    return image + background\n",
    "\n",
    "\n",
    "base_psf_ss = normalize_kernel(jnp.array(base_psf_ss_np, dtype=jnp.float64))\n",
    "base_psf_det = normalize_kernel(downsample_mean(base_psf_ss, factor=SS_FACTOR))\n",
    "k_grid_ss = K_grid(base_psf_ss.shape)\n",
    "k_values_ss = jnp.array(k_grid_ss.k, dtype=jnp.float64)\n",
    "\n",
    "print(\"base ss shape:\", base_psf_ss.shape)\n",
    "print(\"base det shape:\", base_psf_det.shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(np.array(base_psf_ss), origin=\"lower\", norm=\"log\")\n",
    "axes[0].set_title(\"Base PSF (ss grid)\")\n",
    "axes[1].imshow(np.array(base_psf_det), origin=\"lower\", norm=\"log\")\n",
    "axes[1].set_title(\"Base PSF (detector grid)\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Model: STPSF + (Matern + WN Fourier correction) + resize + per-star nuisance\n",
    "# Flux is solved analytically per star (weighted least squares), not sampled.\n",
    "# Correction field is projected to have zero 0th/1st moments (no total-flux or centroid drift).\n",
    "# Mask support: mask_data=1 uses pixel, 0 excludes pixel from fit/likelihood.\n",
    "# -----------------------------\n",
    "def weighted_ls_flux(unit_model_stack, data_minus_bkg, err_stack, mask_data, eps=1e-12):\n",
    "    inv_var = mask_data / (err_stack**2 + eps)\n",
    "    numer = jnp.sum(unit_model_stack * data_minus_bkg * inv_var, axis=(1, 2))\n",
    "    denom = jnp.sum((unit_model_stack**2) * inv_var, axis=(1, 2)) + eps\n",
    "    flux = numer / denom\n",
    "    return jnp.clip(flux, eps, jnp.inf)\n",
    "\n",
    "\n",
    "def project_zero_moments(corr, eps=1e-12):\n",
    "    ny, nx = corr.shape\n",
    "    yy, xx = jnp.indices((ny, nx), dtype=corr.dtype)\n",
    "    xx = xx - (nx - 1) / 2.0\n",
    "    yy = yy - (ny - 1) / 2.0\n",
    "\n",
    "    b0 = jnp.ones_like(corr)\n",
    "    bx = xx\n",
    "    by = yy\n",
    "\n",
    "    d = corr.reshape(-1)\n",
    "    B = jnp.stack([b0.reshape(-1), bx.reshape(-1), by.reshape(-1)], axis=1)\n",
    "\n",
    "    BtB = B.T @ B\n",
    "    Btd = B.T @ d\n",
    "    coeff = jnp.linalg.solve(BtB + eps * jnp.eye(3, dtype=corr.dtype), Btd)\n",
    "    d_proj = d - B @ coeff\n",
    "    return d_proj.reshape(ny, nx)\n",
    "\n",
    "\n",
    "def model_psf_svi(sci_data, err_data, mask_data, flux_loc, bkg_loc, bkg_scale, base_psf_ss, k_values):\n",
    "    _ = flux_loc\n",
    "\n",
    "    corr_dict = matern_power_spectrum(\n",
    "        \"PSF correction\",\n",
    "        \"psf_corr\",\n",
    "        k_values,\n",
    "        n_value=None,\n",
    "        positive=False,\n",
    "    )\n",
    "    corr_ss_raw = corr_dict[\"pixels\"]\n",
    "    corr_ss = project_zero_moments(corr_ss_raw)\n",
    "    numpyro.deterministic(\"pixels_psf_corr_proj\", corr_ss)\n",
    "\n",
    "    psf_ss_raw = base_psf_ss + corr_ss\n",
    "    psf_ss_pos = jax.nn.softplus(100.0 * psf_ss_raw) / 100.0\n",
    "    psf_ss_model = psf_ss_pos / jnp.sum(psf_ss_pos)\n",
    "    numpyro.deterministic(\"psf_ss_model\", psf_ss_model)\n",
    "\n",
    "    psf_det_model = downsample_mean(psf_ss_model, factor=SS_FACTOR)\n",
    "    psf_det_model = psf_det_model / jnp.sum(psf_det_model)\n",
    "    numpyro.deterministic(\"psf_det_model\", psf_det_model)\n",
    "\n",
    "    base_det = downsample_mean(base_psf_ss, factor=SS_FACTOR)\n",
    "    base_det = base_det / jnp.sum(base_det)\n",
    "    numpyro.deterministic(\"psf_corr_ss_eff\", psf_ss_model - base_psf_ss)\n",
    "    numpyro.deterministic(\"psf_corr_det_eff\", psf_det_model - base_det)\n",
    "\n",
    "    n_star = sci_data.shape[0]\n",
    "    with numpyro.plate(\"stars\", n_star):\n",
    "        x_pos = numpyro.sample(\n",
    "            \"x_pos\",\n",
    "            dist.TruncatedNormal(\n",
    "                loc=jnp.zeros(n_star),\n",
    "                scale=XPOS_PRIOR_SIGMA,\n",
    "                low=XPOS_BOUNDS[0],\n",
    "                high=XPOS_BOUNDS[1],\n",
    "            ),\n",
    "        )\n",
    "        y_pos = numpyro.sample(\n",
    "            \"y_pos\",\n",
    "            dist.TruncatedNormal(\n",
    "                loc=jnp.zeros(n_star),\n",
    "                scale=YPOS_PRIOR_SIGMA,\n",
    "                low=YPOS_BOUNDS[0],\n",
    "                high=YPOS_BOUNDS[1],\n",
    "            ),\n",
    "        )\n",
    "        background = numpyro.sample(\n",
    "            \"background\",\n",
    "            dist.Normal(loc=bkg_loc, scale=bkg_scale),\n",
    "        )\n",
    "\n",
    "    unit_model_stack = jax.vmap(render_single_star, in_axes=(None, 0, 0, 0, 0))(\n",
    "        psf_det_model,\n",
    "        x_pos,\n",
    "        y_pos,\n",
    "        jnp.ones_like(x_pos),\n",
    "        jnp.zeros_like(background),\n",
    "    )\n",
    "    data_minus_bkg = sci_data - background[:, None, None]\n",
    "    flux_opt = weighted_ls_flux(unit_model_stack, data_minus_bkg, err_data, mask_data)\n",
    "    numpyro.deterministic(\"flux_opt\", flux_opt)\n",
    "    numpyro.deterministic(\"log10_flux_opt\", jnp.log10(flux_opt))\n",
    "\n",
    "    model_stack = unit_model_stack * flux_opt[:, None, None] + background[:, None, None]\n",
    "\n",
    "    # masked Gaussian log-likelihood\n",
    "    logp = dist.Normal(model_stack, err_data).log_prob(sci_data)\n",
    "    logp = jnp.where(mask_data > 0.5, logp, 0.0)\n",
    "    numpyro.factor(\"obs_masked\", jnp.sum(logp))\n",
    "\n",
    "\n",
    "rng_key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "init_fun = infer.init_to_median(num_samples=15)\n",
    "guide = autoguide.AutoDiagonalNormal(model_psf_svi, init_loc_fn=init_fun, init_scale=0.02)\n",
    "\n",
    "scheduler = split_scheduler(MAX_ITERATIONS, init_value=0.01, transition_steps=TRANSITION_STEPS)\n",
    "optim = optax.adabelief(learning_rate=scheduler)\n",
    "loss = infer.TraceMeanField_ELBO()\n",
    "\n",
    "svi = SVI_vec(model_psf_svi, guide, optim, loss)\n",
    "\n",
    "svi_results = svi.run(\n",
    "    rng_key,\n",
    "    NUM_CHAINS,\n",
    "    MAX_ITERATIONS,\n",
    "    sci_stack,\n",
    "    err_stack,\n",
    "    mask_stack,\n",
    "    flux_loc,\n",
    "    bkg_loc,\n",
    "    bkg_scale,\n",
    "    base_psf_ss,\n",
    "    k_values_ss,\n",
    "    stable_update=True,\n",
    ")\n",
    "\n",
    "losses_np = np.array(jax.device_get(svi_results.losses))\n",
    "final_losses = losses_np[:, -1]\n",
    "best_chain = int(np.argmin(final_losses))\n",
    "print(\"Final losses:\", final_losses)\n",
    "print(\"Best chain:\", best_chain)\n",
    "\n",
    "params_best = jax.tree.map(lambda v: v[best_chain], svi_results.params)\n",
    "median_best = guide.median(params_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Posterior samples and required posteriors\n",
    "# -----------------------------\n",
    "rng_key, sample_key, pred_key = jax.random.split(rng_key, 3)\n",
    "\n",
    "posterior_latent = guide.sample_posterior(\n",
    "    sample_key,\n",
    "    params_best,\n",
    "    sample_shape=(NUM_POST_SAMPLES,),\n",
    ")\n",
    "\n",
    "return_sites = [\n",
    "    \"psf_ss_model\",\n",
    "    \"psf_det_model\",\n",
    "    \"pixels_psf_corr\",\n",
    "    \"pixels_psf_corr_proj\",\n",
    "    \"psf_corr_ss_eff\",\n",
    "    \"psf_corr_det_eff\",\n",
    "    \"n_psf_corr\",\n",
    "    \"rho_psf_corr\",\n",
    "    \"sigma_psf_corr\",\n",
    "    \"x_pos\",\n",
    "    \"y_pos\",\n",
    "    \"background\",\n",
    "    \"flux_opt\",\n",
    "    \"log10_flux_opt\",\n",
    "]\n",
    "\n",
    "predictive = infer.Predictive(\n",
    "    model_psf_svi,\n",
    "    posterior_samples=posterior_latent,\n",
    "    return_sites=return_sites,\n",
    ")\n",
    "\n",
    "posterior = predictive(\n",
    "    pred_key,\n",
    "    sci_stack,\n",
    "    err_stack,\n",
    "    mask_stack,\n",
    "    flux_loc,\n",
    "    bkg_loc,\n",
    "    bkg_scale,\n",
    "    base_psf_ss,\n",
    "    k_values_ss,\n",
    ")\n",
    "\n",
    "n_post = np.array(jax.device_get(posterior[\"n_psf_corr\"]))[:, 0]\n",
    "rho_post = np.array(jax.device_get(posterior[\"rho_psf_corr\"]))[:, 0]\n",
    "sigma_post = np.array(jax.device_get(posterior[\"sigma_psf_corr\"]))[:, 0]\n",
    "\n",
    "psf_ss_median = np.median(np.array(jax.device_get(posterior[\"psf_ss_model\"])), axis=0)\n",
    "psf_det_median = np.median(np.array(jax.device_get(posterior[\"psf_det_model\"])), axis=0)\n",
    "pixcorr_median = np.median(np.array(jax.device_get(posterior[\"pixels_psf_corr_proj\"])), axis=0)\n",
    "\n",
    "summary = {\n",
    "    \"n_median\": float(np.median(n_post)),\n",
    "    \"n_p16\": float(np.percentile(n_post, 16)),\n",
    "    \"n_p84\": float(np.percentile(n_post, 84)),\n",
    "    \"rho_median\": float(np.median(rho_post)),\n",
    "    \"rho_p16\": float(np.percentile(rho_post, 16)),\n",
    "    \"rho_p84\": float(np.percentile(rho_post, 84)),\n",
    "    \"sigma_median\": float(np.median(sigma_post)),\n",
    "    \"sigma_p16\": float(np.percentile(sigma_post, 16)),\n",
    "    \"sigma_p84\": float(np.percentile(sigma_post, 84)),\n",
    "}\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d10ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Visual diagnostics\n",
    "# -----------------------------\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "\n",
    "for i in range(losses_np.shape[0]):\n",
    "    axes[0, 0].plot(losses_np[i], alpha=0.7, label=f\"chain {i}\")\n",
    "axes[0, 0].set_yscale(\"asinh\")\n",
    "axes[0, 0].set_title(\"SVI loss\")\n",
    "axes[0, 0].legend(loc=\"best\", fontsize=8)\n",
    "\n",
    "im1 = axes[0, 1].imshow(np.array(base_psf_det), origin=\"lower\", norm=\"log\")\n",
    "axes[0, 1].set_title(\"Base STPSF (det)\")\n",
    "plt.colorbar(im1, ax=axes[0, 1], fraction=0.046, pad=0.04)\n",
    "\n",
    "im2 = axes[0, 2].imshow(psf_det_median, origin=\"lower\", norm=\"log\")\n",
    "axes[0, 2].set_title(\"Model PSF median (det)\")\n",
    "plt.colorbar(im2, ax=axes[0, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "im3 = axes[1, 0].imshow(pixcorr_median, origin=\"lower\")\n",
    "axes[1, 0].set_title(\"pixels_psf_corr median (ss)\")\n",
    "plt.colorbar(im3, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
    "\n",
    "axes[1, 1].hist(n_post, bins=30, alpha=0.8)\n",
    "axes[1, 1].set_title(\"Posterior of n_psf_corr\")\n",
    "\n",
    "axes[1, 2].hist(rho_post, bins=30, alpha=0.8)\n",
    "axes[1, 2].set_xscale(\"log\")\n",
    "axes[1, 2].set_title(\"Posterior of rho_psf_corr\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Save SVI outputs (no HMC)\n",
    "# -----------------------------\n",
    "output_fits = os.path.join(OUTPUT_DIR, f\"PSF_model_step3_svi{OUTPUT_SUFFIX}.fits\")\n",
    "output_info = os.path.join(OUTPUT_DIR, f\"PSF_model_info_step3_svi{OUTPUT_SUFFIX}.npz\")\n",
    "\n",
    "pixels_wn_post = np.array(jax.device_get(posterior_latent[\"pixels_wn_psf_corr\"]))\n",
    "pixels_wn_median = np.median(pixels_wn_post, axis=0)\n",
    "\n",
    "corr_proj_median = np.median(np.array(jax.device_get(posterior[\"pixels_psf_corr_proj\"])), axis=0)\n",
    "corr_eff_ss_median = np.median(np.array(jax.device_get(posterior[\"psf_corr_ss_eff\"])), axis=0)\n",
    "corr_eff_det_median = np.median(np.array(jax.device_get(posterior[\"psf_corr_det_eff\"])), axis=0)\n",
    "\n",
    "hdr = fits.Header()\n",
    "hdr[\"NSTAR\"] = int(n_star)\n",
    "hdr[\"PIXSCALE\"] = float(PIX_SCALE)\n",
    "hdr[\"SSFACT\"] = int(SS_FACTOR)\n",
    "hdr[\"NPOST\"] = int(NUM_POST_SAMPLES)\n",
    "hdr[\"NMED\"] = float(summary[\"n_median\"])\n",
    "hdr[\"RHOMED\"] = float(summary[\"rho_median\"])\n",
    "hdr[\"SIGMED\"] = float(summary[\"sigma_median\"])\n",
    "hdr[\"SMOKE\"] = (int(SMOKE_TEST), \"1 if smoke-test run\")\n",
    "\n",
    "hdul = fits.HDUList([\n",
    "    fits.PrimaryHDU(header=hdr),\n",
    "    fits.ImageHDU(data=np.array(psf_ss_median, dtype=np.float32), name=\"SS_PSF_MODEL\"),\n",
    "    fits.ImageHDU(data=np.array(psf_det_median, dtype=np.float32), name=\"DET_PSF_MODEL\"),\n",
    "    fits.ImageHDU(data=np.array(corr_proj_median, dtype=np.float32), name=\"CORR_PROJ_SS\"),\n",
    "    fits.ImageHDU(data=np.array(corr_eff_ss_median, dtype=np.float32), name=\"CORR_EFF_SS\"),\n",
    "    fits.ImageHDU(data=np.array(corr_eff_det_median, dtype=np.float32), name=\"CORR_EFF_DET\"),\n",
    "    fits.ImageHDU(data=np.array(pixels_wn_median, dtype=np.float32), name=\"NOISE_WN_MED\"),\n",
    "    fits.ImageHDU(data=np.array(k_values_ss, dtype=np.float32), name=\"K_GRID\"),\n",
    "])\n",
    "hdul.writeto(output_fits, overwrite=True)\n",
    "\n",
    "np.savez(\n",
    "    output_info,\n",
    "    n_post=n_post,\n",
    "    rho_post=rho_post,\n",
    "    sigma_post=sigma_post,\n",
    "    n_median=np.float64(summary[\"n_median\"]),\n",
    "    rho_median=np.float64(summary[\"rho_median\"]),\n",
    "    sigma_median=np.float64(summary[\"sigma_median\"]),\n",
    "    pixels_wn_median=np.array(pixels_wn_median, dtype=np.float32),\n",
    "    pixels_corr_proj_median=np.array(corr_proj_median, dtype=np.float32),\n",
    "    psf_det_median=np.array(psf_det_median, dtype=np.float32),\n",
    ")\n",
    "\n",
    "print(\"saved:\", output_fits)\n",
    "print(\"saved:\", output_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Result display requested:\n",
    "# - STPSF psf and modeled psf\n",
    "# - global correction field\n",
    "# - all stars: star, model, residual\n",
    "# -----------------------------\n",
    "x_med = np.median(np.array(jax.device_get(posterior[\"x_pos\"])), axis=0)\n",
    "y_med = np.median(np.array(jax.device_get(posterior[\"y_pos\"])), axis=0)\n",
    "flux_med = np.median(np.array(jax.device_get(posterior[\"flux_opt\"])), axis=0)\n",
    "bkg_med = np.median(np.array(jax.device_get(posterior[\"background\"])), axis=0)\n",
    "\n",
    "\n",
    "# Model PSF-only image for each star (background fixed to 0)\n",
    "psf_only_med = jax.vmap(render_single_star, in_axes=(None, 0, 0, 0, 0))(\n",
    "    jnp.array(psf_det_median),\n",
    "    jnp.array(x_med),\n",
    "    jnp.array(y_med),\n",
    "    jnp.array(flux_med),\n",
    "    jnp.zeros_like(jnp.array(bkg_med)),\n",
    ")\n",
    "psf_only_med = np.array(jax.device_get(psf_only_med))\n",
    "\n",
    "data_np = np.array(jax.device_get(sci_stack))\n",
    "err_np = np.array(jax.device_get(err_stack))\n",
    "bkg_cube = bkg_med[:, None, None]\n",
    "\n",
    "star_img = data_np - bkg_cube\n",
    "residual = (data_np - psf_only_med - bkg_cube) / err_np\n",
    "\n",
    "# (A) STPSF detector PSF and model detector PSF\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n",
    "im0 = axes[0].imshow(np.array(base_psf_det), origin=\"lower\", norm=\"log\")\n",
    "axes[0].set_title(\"STPSF (detector)\")\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "im1 = axes[1].imshow(np.array(psf_det_median), origin=\"lower\", norm=\"log\")\n",
    "axes[1].set_title(\"Model PSF (detector)\")\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "\n",
    "# (B) Global correction field (single field, not per-star)\n",
    "global_corr_ss = np.array(psf_ss_median) - np.array(base_psf_ss)\n",
    "global_corr_det = np.array(psf_det_median) - np.array(base_psf_det)\n",
    "\n",
    "abs_corr_ss = np.max(np.abs(global_corr_ss))\n",
    "if abs_corr_ss <= 0:\n",
    "    abs_corr_ss = 1.0\n",
    "abs_corr_det = np.max(np.abs(global_corr_det))\n",
    "if abs_corr_det <= 0:\n",
    "    abs_corr_det = 1.0\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "im2 = axes[0].imshow(global_corr_ss, origin=\"lower\", cmap=\"coolwarm\", vmin=-abs_corr_ss, vmax=abs_corr_ss)\n",
    "axes[0].set_title(\"Global correction field (SS)\")\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "plt.colorbar(im2, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "im3 = axes[1].imshow(global_corr_det, origin=\"lower\", cmap=\"coolwarm\", vmin=-abs_corr_det, vmax=abs_corr_det)\n",
    "axes[1].set_title(\"Global correction field (detector)\")\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "plt.colorbar(im3, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "\n",
    "# (C) Show all stars with 3 panels each: star / model / residual\n",
    "n_show = star_img.shape[0]\n",
    "chunk_size = 7  # rows per figure\n",
    "\n",
    "star_vmin, star_vmax = np.percentile(star_img, [1.0, 99.5])\n",
    "model_vmin, model_vmax = np.percentile(psf_only_med, [1.0, 99.5])\n",
    "\n",
    "for start in range(0, n_show, chunk_size):\n",
    "    stop = min(start + chunk_size, n_show)\n",
    "    nrows = stop - start\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, 3, figsize=(9.5, 2.6 * nrows), constrained_layout=True)\n",
    "    axes = np.array(axes)\n",
    "    if nrows == 1:\n",
    "        axes = axes[None, :]\n",
    "\n",
    "    for r, i in enumerate(range(start, stop)):\n",
    "        im_star = axes[r, 0].imshow(star_img[i], origin=\"lower\", cmap=\"viridis\", vmin=star_vmin, vmax=star_vmax)\n",
    "        axes[r, 0].set_title(f\"star {i}: data-bkg\", fontsize=9)\n",
    "\n",
    "        im_model = axes[r, 1].imshow(psf_only_med[i], origin=\"lower\", cmap=\"viridis\", vmin=model_vmin, vmax=model_vmax)\n",
    "        axes[r, 1].set_title(\"model\", fontsize=9)\n",
    "\n",
    "        im_res = axes[r, 2].imshow(residual[i], origin=\"lower\", cmap=\"bwr\", vmin=-3, vmax=3)\n",
    "        axes[r, 2].set_title(\"residual\", fontsize=9)\n",
    "\n",
    "        for c in range(3):\n",
    "            axes[r, c].set_xticks([])\n",
    "            axes[r, c].set_yticks([])\n",
    "\n",
    "    fig.colorbar(im_star, ax=axes[:, 0].tolist(), fraction=0.02, pad=0.01)\n",
    "    fig.colorbar(im_model, ax=axes[:, 1].tolist(), fraction=0.02, pad=0.01)\n",
    "    fig.colorbar(im_res, ax=axes[:, 2].tolist(), fraction=0.02, pad=0.01)\n",
    "\n",
    "    fig.suptitle(f\"Stars {start} - {stop-1}: star / model / residual\", fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
