{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09140846",
   "metadata": {},
   "source": [
    "# Detect Four Point Sources (WFI2033)\n",
    "\n",
    "This notebook detects the four brightest point-like sources in the JWST cutout,\n",
    "reports their pixel positions, converts them to arcsec coordinates using `pix_scale=0.031`\n",
    "assuming image center is `(0, 0)`, and estimates rough fluxes with aperture photometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b2a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from photutils.detection import DAOStarFinder\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus, aperture_photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884bfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "pix_scale = 0.031  # arcsec / pixel\n",
    "\n",
    "CANDIDATE_DATA_DIRS = [\n",
    "    \"../Data/WFI2033\",\n",
    "    \"../Herculens/Data/WFI2033\",\n",
    "    \"/mnt/d/lensing/Herculens/Data/WFI2033\",\n",
    "]\n",
    "\n",
    "DATA_DIR = None\n",
    "for d in CANDIDATE_DATA_DIRS:\n",
    "    if os.path.exists(d):\n",
    "        DATA_DIR = d\n",
    "        break\n",
    "if DATA_DIR is None:\n",
    "    raise FileNotFoundError(f\"Cannot find WFI2033 directory. Tried: {CANDIDATE_DATA_DIRS}\")\n",
    "\n",
    "raw_data_path = os.path.join(DATA_DIR, \"jw01198-o004_t004_nircam_clear-f115w_i2d.fits\")\n",
    "data_path = os.path.join(DATA_DIR, \"jw01198-o004_t004_nircam_clear-f115w_i2d_cut_x6985_y3594_150.fits\")\n",
    "mask_path = os.path.join(DATA_DIR, \"mask.fits\")\n",
    "mask_out_path = os.path.join(DATA_DIR, \"mask_out.fits\")\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"data_path:\", data_path)\n",
    "print(\"mask_path:\", mask_path)\n",
    "print(\"mask_out_path:\", mask_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image + error + masks + exposure time\n",
    "with fits.open(raw_data_path, memmap=True) as hdul_raw:\n",
    "    exposure_time = float(hdul_raw[\"SCI\"].header[\"XPOSURE\"])\n",
    "\n",
    "with fits.open(data_path, memmap=True) as hdul:\n",
    "    data = np.array(hdul[\"SCI\"].data, dtype=float)\n",
    "    err = np.array(hdul[\"ERR\"].data, dtype=float)\n",
    "\n",
    "mask = np.array(fits.getdata(mask_path), dtype=bool)\n",
    "mask_out_raw = np.array(fits.getdata(mask_out_path))\n",
    "mask_out = np.array(1 - mask_out_raw, dtype=bool)\n",
    "\n",
    "valid = np.isfinite(data) & np.isfinite(err) & (err > 0) & mask & mask_out\n",
    "\n",
    "if data.shape != err.shape or data.shape != mask.shape or data.shape != mask_out.shape:\n",
    "    raise ValueError(\n",
    "        f\"Shape mismatch: data={data.shape}, err={err.shape}, mask={mask.shape}, mask_out={mask_out.shape}\"\n",
    "    )\n",
    "\n",
    "print(\"shape:\", data.shape)\n",
    "print(\"exposure_time:\", exposure_time)\n",
    "print(\"valid pixels:\", int(valid.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832959d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build working image for peak finding\n",
    "work = data.copy()\n",
    "median_fill = np.nanmedian(data[valid])\n",
    "work[~valid] = median_fill\n",
    "\n",
    "mean, med, std = sigma_clipped_stats(work[valid], sigma=3.0)\n",
    "print(\"sigma-clipped stats:\", {\"mean\": float(mean), \"median\": float(med), \"std\": float(std)})\n",
    "\n",
    "# STARRED-style DAOStarFinder baseline\n",
    "daofind = DAOStarFinder(\n",
    "    fwhm=2.5,           # in pixels\n",
    "    threshold=5.0*std,  # detection threshold\n",
    "    exclude_border=True,\n",
    ")\n",
    "\n",
    "sources = daofind(work - med)\n",
    "if sources is None or len(sources) == 0:\n",
    "    raise RuntimeError(\"No sources found. Try lower threshold or adjust fwhm.\")\n",
    "\n",
    "print(\"detected sources:\", len(sources))\n",
    "sources.sort(\"peak\")\n",
    "sources = sources[::-1]  # brightest first\n",
    "sources[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 4 distinct brightest peaks with a minimum separation\n",
    "N_SELECT = 4\n",
    "MIN_SEP_PIX = 4.0\n",
    "\n",
    "selected_rows = []\n",
    "selected_pos = []\n",
    "for row in sources:\n",
    "    x = float(row[\"xcentroid\"])\n",
    "    y = float(row[\"ycentroid\"])\n",
    "    if all(np.hypot(x - sx, y - sy) >= MIN_SEP_PIX for sx, sy in selected_pos):\n",
    "        selected_rows.append(row)\n",
    "        selected_pos.append((x, y))\n",
    "    if len(selected_rows) == N_SELECT:\n",
    "        break\n",
    "\n",
    "if len(selected_rows) < N_SELECT:\n",
    "    raise RuntimeError(f\"Only found {len(selected_rows)} distinct sources; expected {N_SELECT}.\")\n",
    "\n",
    "positions = np.array(selected_pos)\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd2c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough flux estimation with aperture photometry\n",
    "# flux ~ aperture_sum - local_background * aperture_area\n",
    "r_ap = 3.0\n",
    "r_in, r_out = 5.0, 8.0\n",
    "\n",
    "ap = CircularAperture(positions, r=r_ap)\n",
    "an = CircularAnnulus(positions, r_in=r_in, r_out=r_out)\n",
    "\n",
    "phot_ap = aperture_photometry(work, ap)\n",
    "phot_an = aperture_photometry(work, an)\n",
    "\n",
    "x0 = (work.shape[1] - 1) / 2.0\n",
    "y0 = (work.shape[0] - 1) / 2.0\n",
    "\n",
    "rows = []\n",
    "for i, (x, y) in enumerate(positions, start=1):\n",
    "    bkg = float(phot_an[\"aperture_sum\"][i-1] / an.area)\n",
    "    flux = float(phot_ap[\"aperture_sum\"][i-1] - bkg * ap.area)\n",
    "\n",
    "    x_arcsec = (x - x0) * pix_scale\n",
    "    y_arcsec = (y - y0) * pix_scale\n",
    "\n",
    "    rows.append({\n",
    "        \"id\": i,\n",
    "        \"x_pix\": x,\n",
    "        \"y_pix\": y,\n",
    "        \"x_pix_1based\": x + 1.0,\n",
    "        \"y_pix_1based\": y + 1.0,\n",
    "        \"x_arcsec_centered\": x_arcsec,\n",
    "        \"y_arcsec_centered\": y_arcsec,\n",
    "        \"flux_aperture_bgsub\": flux,\n",
    "        \"local_bkg_per_pix\": bkg,\n",
    "    })\n",
    "\n",
    "result = pd.DataFrame(rows).sort_values(\"flux_aperture_bgsub\", ascending=False).reset_index(drop=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detections\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "im = ax.imshow(work, origin=\"lower\", cmap=\"gray\", norm=colors.LogNorm(vmin=np.percentile(work[valid], 5), vmax=np.percentile(work[valid], 99.9)))\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ap.plot(ax=ax, color=\"cyan\", lw=1.5)\n",
    "for _, r in result.iterrows():\n",
    "    ax.text(r[\"x_pix\"] + 2, r[\"y_pix\"] + 2, f\"{int(r['id'])}\", color=\"yellow\", fontsize=12, weight=\"bold\")\n",
    "\n",
    "ax.set_title(\"Detected 4 Point Sources\")\n",
    "ax.set_xlabel(\"x [pix]\")\n",
    "ax.set_ylabel(\"y [pix]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save result table\n",
    "out_csv = \"point_sources_wfi2033_4sources.csv\"\n",
    "result.to_csv(out_csv, index=False)\n",
    "out_csv"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
